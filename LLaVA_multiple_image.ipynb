{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HireTheHero/Machine_Notebooks/blob/main/LLaVA_multiple_image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziWgeQeeg1s7"
      },
      "source": [
        "# Example notebook for running with multiple images\n",
        "- Operational in colab pro+"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zu3cKH8g-uS"
      },
      "source": [
        "# init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJDO3iM8gPEW",
        "outputId": "e3ef1f26-c8ca-4cff-b21c-d2b01225fea5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LLaVA'...\n",
            "remote: Enumerating objects: 1549, done.\u001b[K\n",
            "remote: Counting objects: 100% (645/645), done.\u001b[K\n",
            "remote: Compressing objects: 100% (248/248), done.\u001b[K\n",
            "remote: Total 1549 (delta 526), reused 416 (delta 397), pack-reused 904\u001b[K\n",
            "Receiving objects: 100% (1549/1549), 12.38 MiB | 12.35 MiB/s, done.\n",
            "Resolving deltas: 100% (982/982), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/HireTheHero/LLaVA.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4b4ybnphYkt",
        "outputId": "a163f2d8-8128-4bc5-a07b-4140d07ee9a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.3-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.3\n",
            "Obtaining file:///content/LLaVA\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting einops (from llava==1.1.1)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting fastapi (from llava==1.1.1)\n",
            "  Downloading fastapi-0.104.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting gradio==3.35.2 (from llava==1.1.1)\n",
            "  Downloading gradio-3.35.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting markdown2[all] (from llava==1.1.1)\n",
            "  Downloading markdown2-2.4.10-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llava==1.1.1) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from llava==1.1.1) (2.31.0)\n",
            "Collecting sentencepiece (from llava==1.1.1)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers>=0.12.1 (from llava==1.1.1)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting torch==2.0.1 (from llava==1.1.1)\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.15.2 (from llava==1.1.1)\n",
            "  Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m115.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn (from llava==1.1.1)\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting wandb (from llava==1.1.1)\n",
            "  Downloading wandb-0.15.12-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting shortuuid (from llava==1.1.1)\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Collecting httpx==0.24.0 (from llava==1.1.1)\n",
            "  Downloading httpx-0.24.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deepspeed==0.9.5 (from llava==1.1.1)\n",
            "  Downloading deepspeed-0.9.5.tar.gz (809 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.9/809.9 kB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting peft==0.4.0 (from llava==1.1.1)\n",
            "  Downloading peft-0.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting transformers==4.31.0 (from llava==1.1.1)\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl.metadata (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate==0.21.0 (from llava==1.1.1)\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting bitsandbytes==0.41.0 (from llava==1.1.1)\n",
            "  Downloading bitsandbytes-0.41.0-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.10/dist-packages (from llava==1.1.1) (1.2.2)\n",
            "Collecting einops (from llava==1.1.1)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops-exts==0.0.4 (from llava==1.1.1)\n",
            "  Downloading einops_exts-0.0.4-py3-none-any.whl (3.9 kB)\n",
            "Collecting timm==0.6.13 (from llava==1.1.1)\n",
            "  Downloading timm-0.6.13-py3-none-any.whl (549 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio-client==0.2.9 (from llava==1.1.1)\n",
            "  Downloading gradio_client-0.2.9-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0->llava==1.1.1) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0->llava==1.1.1) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0->llava==1.1.1) (6.0.1)\n",
            "Collecting hjson (from deepspeed==0.9.5->llava==1.1.1)\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from deepspeed==0.9.5->llava==1.1.1)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.9.5->llava==1.1.1) (9.0.0)\n",
            "Requirement already satisfied: pydantic<2.0.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.9.5->llava==1.1.1) (1.10.13)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.9.5->llava==1.1.1) (4.66.1)\n",
            "Collecting aiofiles (from gradio==3.35.2->llava==1.1.1)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->llava==1.1.1) (3.8.6)\n",
            "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->llava==1.1.1) (4.2.2)\n",
            "Collecting ffmpy (from gradio==3.35.2->llava==1.1.1)\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting huggingface-hub>=0.14.0 (from gradio==3.35.2->llava==1.1.1)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->llava==1.1.1) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.35.2->llava==1.1.1) (3.0.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->llava==1.1.1) (2.1.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->llava==1.1.1) (3.7.1)\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio==3.35.2->llava==1.1.1)\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson (from gradio==3.35.2->llava==1.1.1)\n",
            "  Downloading orjson-3.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->llava==1.1.1) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->llava==1.1.1) (9.4.0)\n",
            "Collecting pydub (from gradio==3.35.2->llava==1.1.1)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->llava==1.1.1) (2.16.1)\n",
            "Collecting python-multipart (from gradio==3.35.2->llava==1.1.1)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version (from gradio==3.35.2->llava==1.1.1)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting websockets>=10.0 (from gradio==3.35.2->llava==1.1.1)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.2.9->llava==1.1.1) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.2.9->llava==1.1.1) (4.5.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.0->llava==1.1.1) (2023.7.22)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx==0.24.0->llava==1.1.1)\n",
            "  Downloading httpcore-0.17.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.0->llava==1.1.1) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.0->llava==1.1.1) (1.3.0)\n",
            "Collecting safetensors (from peft==0.4.0->llava==1.1.1)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->llava==1.1.1) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->llava==1.1.1) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->llava==1.1.1) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->llava==1.1.1) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->llava==1.1.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->llava==1.1.1) (3.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1->llava==1.1.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1->llava==1.1.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1->llava==1.1.1)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m124.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1->llava==1.1.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1->llava==1.1.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1->llava==1.1.1)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1->llava==1.1.1)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1->llava==1.1.1)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1->llava==1.1.1)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1->llava==1.1.1)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1->llava==1.1.1)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0 (from torch==2.0.1->llava==1.1.1)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->llava==1.1.1) (2023.6.3)\n",
            "Collecting tokenizers>=0.12.1 (from llava==1.1.1)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m120.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->llava==1.1.1) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->llava==1.1.1) (0.41.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->llava==1.1.1) (3.27.7)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1->llava==1.1.1)\n",
            "  Downloading lit-17.0.3.tar.gz (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llava==1.1.1) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn->llava==1.1.1)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->llava==1.1.1) (3.7.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->llava==1.1.1)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting typing-extensions (from gradio-client==0.2.9->llava==1.1.1)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting wavedrom (from markdown2[all]->llava==1.1.1)\n",
            "  Downloading wavedrom-2.0.3.post3.tar.gz (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->llava==1.1.1) (3.3.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->llava==1.1.1) (2.0.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->llava==1.1.1)\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->llava==1.1.1)\n",
            "  Downloading sentry_sdk-1.32.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb->llava==1.1.1)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools (from wandb->llava==1.1.1)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb->llava==1.1.1)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->llava==1.1.1) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->llava==1.1.1) (3.20.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio==3.35.2->llava==1.1.1) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio==3.35.2->llava==1.1.1) (4.19.1)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio==3.35.2->llava==1.1.1) (0.12.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->llava==1.1.1) (1.1.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->llava==1.1.1) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->llava==1.1.1)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.0.0->markdown-it-py[linkify]>=2.0.0->gradio==3.35.2->llava==1.1.1) (0.1.2)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.35.2->llava==1.1.1) (2.0.2)\n",
            "INFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio==3.35.2->llava==1.1.1)\n",
            "  Downloading mdit_py_plugins-0.3.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.8-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.7-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.6-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.5-py3-none-any.whl (39 kB)\n",
            "INFO: pip is still looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading mdit_py_plugins-0.2.4-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.3-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.2-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.1-py3-none-any.whl (38 kB)\n",
            "  Downloading mdit_py_plugins-0.2.0-py3-none-any.whl (38 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading mdit_py_plugins-0.1.0-py3-none-any.whl (37 kB)\n",
            "Collecting markdown-it-py[linkify]>=2.0.0 (from gradio==3.35.2->llava==1.1.1)\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio==3.35.2->llava==1.1.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio==3.35.2->llava==1.1.1) (2023.3.post1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.35.2->llava==1.1.1) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.35.2->llava==1.1.1) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.35.2->llava==1.1.1) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.35.2->llava==1.1.1) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.35.2->llava==1.1.1) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.35.2->llava==1.1.1) (1.3.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.35.2->llava==1.1.1) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.35.2->llava==1.1.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.35.2->llava==1.1.1) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.35.2->llava==1.1.1) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.35.2->llava==1.1.1) (3.1.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->llava==1.1.1) (1.3.0)\n",
            "Collecting svgwrite (from wavedrom->markdown2[all]->llava==1.1.1)\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->llava==1.1.1)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.35.2->llava==1.1.1) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.35.2->llava==1.1.1) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.35.2->llava==1.1.1) (0.10.6)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.35.2->llava==1.1.1) (1.0.2)\n",
            "Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.41.0-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-3.35.2-py3-none-any.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-0.2.9-py3-none-any.whl (288 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.8/288.8 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.4.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m119.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.104.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wandb-0.15.12-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-1.32.0-py2.py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.0/241.0 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading markdown2-2.4.10-py2.py3-none-any.whl (39 kB)\n",
            "Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: llava, deepspeed, ffmpy, pathtools, wavedrom, lit\n",
            "  Building editable for llava (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llava: filename=llava-1.1.1-0.editable-py3-none-any.whl size=14471 sha256=8558d4d18b171fcd59b0492a9e505668896d2015c8eeb38892ee004c7c9e9345\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vgk_cbyf/wheels/04/eb/cc/8992f8302dd174d3e63566efe82795f070b535b03506b75ffb\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.9.5-py3-none-any.whl size=844527 sha256=c476a6f17637cf0902fcb71ccc3a2e8f82ca58ddb7be2cac57db85cd52ec4ff6\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/a9/bb/a00d383521da14dc91b65ae2d0062401b750d968a548401b2a\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=61cbca01873c2d323e78ecf60f6462768736c70cbf47e994b29433bf7f025c4b\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=34efcd05512e61850dee8e8512a020203e6b41e06c7c15e5e08a50dad6fd9588\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "  Building wheel for wavedrom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30052 sha256=b0198183fed6407f8fc7e613b850174f7b9ea400c31a2f5d99c0762a2a263857\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/52/8c/38b454b42f712f325e26f633287484c7dc1ad469e1580c5954\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-17.0.3-py3-none-any.whl size=93257 sha256=e4ff8475fe05673ac5cdb21beaf9c4180010bb456777f4ffe442e06561fdd85d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/b8/42/f6f56aba870f9f3cc895b2e0c970ececaafc7d191217fa10a4\n",
            "Successfully built llava deepspeed ffmpy pathtools wavedrom lit\n",
            "Installing collected packages: tokenizers, sentencepiece, pydub, pathtools, ninja, lit, hjson, ffmpy, bitsandbytes, websockets, typing-extensions, svgwrite, smmap, shortuuid, setproctitle, sentry-sdk, semantic-version, safetensors, python-multipart, orjson, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, markdown2, markdown-it-py, h11, einops, docker-pycreds, aiofiles, wavedrom, uvicorn, starlette, nvidia-cusolver-cu11, nvidia-cudnn-cu11, mdit-py-plugins, huggingface-hub, httpcore, gitdb, einops-exts, transformers, httpx, GitPython, fastapi, wandb, gradio-client, gradio, triton, torch, torchvision, accelerate, timm, peft, deepspeed, llava\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: mdit-py-plugins\n",
            "    Found existing installation: mdit-py-plugins 0.4.0\n",
            "    Uninstalling mdit-py-plugins-0.4.0:\n",
            "      Successfully uninstalled mdit-py-plugins-0.4.0\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu118\n",
            "    Uninstalling torch-2.1.0+cu118:\n",
            "      Successfully uninstalled torch-2.1.0+cu118\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.16.0+cu118\n",
            "    Uninstalling torchvision-0.16.0+cu118:\n",
            "      Successfully uninstalled torchvision-0.16.0+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "tensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.8.0 which is incompatible.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.40 accelerate-0.21.0 aiofiles-23.2.1 bitsandbytes-0.41.0 deepspeed-0.9.5 docker-pycreds-0.4.0 einops-0.6.1 einops-exts-0.0.4 fastapi-0.104.0 ffmpy-0.3.1 gitdb-4.0.11 gradio-3.35.2 gradio-client-0.2.9 h11-0.14.0 hjson-3.1.0 httpcore-0.17.3 httpx-0.24.0 huggingface-hub-0.18.0 lit-17.0.3 llava-1.1.1 markdown-it-py-2.2.0 markdown2-2.4.10 mdit-py-plugins-0.3.3 ninja-1.11.1.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 orjson-3.9.9 pathtools-0.1.2 peft-0.4.0 pydub-0.25.1 python-multipart-0.0.6 safetensors-0.4.0 semantic-version-2.10.0 sentencepiece-0.1.99 sentry-sdk-1.32.0 setproctitle-1.3.3 shortuuid-1.0.11 smmap-5.0.1 starlette-0.27.0 svgwrite-1.4.3 timm-0.6.13 tokenizers-0.13.3 torch-2.0.1 torchvision-0.15.2 transformers-4.31.0 triton-2.0.0 typing-extensions-4.8.0 uvicorn-0.23.2 wandb-0.15.12 wavedrom-2.0.3.post3 websockets-11.0.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip  # enable PEP 660 support\n",
        "!cd /content/LLaVA; pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28ljOFnFhjzl",
        "outputId": "41775af4-3163-4262-e4da-31c9756d88eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (1.11.1.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting flash-attn\n",
            "  Downloading flash_attn-2.3.2.tar.gz (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn) (2.0.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn) (0.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from flash-attn) (23.2)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from flash-attn) (1.11.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->flash-attn) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->flash-attn) (0.41.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->flash-attn) (3.27.7)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->flash-attn) (17.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.3.2-cp310-cp310-linux_x86_64.whl size=30036697 sha256=991b8f2971fe7782514762c440b330a02bc98deb382e4161a97bed858813d93b\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/2a/7d/13ada26139195be2a5eb874c79d79d0d5afcc791bb08ca2052\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: flash-attn\n",
            "Successfully installed flash-attn-2.3.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install ninja\n",
        "!pip install flash-attn --no-build-isolation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gfacq9oL2qeA"
      },
      "source": [
        "# example runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwN-Zl8X2tl4"
      },
      "source": [
        "## reference: one-image run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T49YYxx2zer",
        "outputId": "ee6928a7-a456-4385-f360-e4aa289ae511"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-10-14 11:04:00,058] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-10-14 11:04:01.808522: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n",
            "Loading checkpoint shards: 100% 3/3 [00:20<00:00,  6.97s/it]\n",
            "In the image, there is a dock extending into a lake, with a mountain in the background. The dock is made of wood and appears to be a small pier or a docking area for boats. The scene is set during the day, and the water is calm and clear. The presence of the mountain in the background adds to the serene and picturesque atmosphere of the scene.\n"
          ]
        }
      ],
      "source": [
        "!cd LLaVA; python -m llava.eval.run_llava \\\n",
        "    --model-path liuhaotian/llava-llama-2-13b-chat-lightning-preview  \\\n",
        "    --image-file \"https://llava-vl.github.io/static/images/view.jpg\" \\\n",
        "    --query \"USER: Can you describe this image?\\n<image-placeholder>\\nASSISTANT: \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfbqM8G_23xk",
        "outputId": "bbfc1116-200d-4ba9-e492-fb181f718dab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-10-14 11:05:25,208] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-10-14 11:05:26.952173: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n",
            "Loading checkpoint shards: 100% 3/3 [00:20<00:00,  6.95s/it]\n",
            "In the image, there is a small toy horse with glasses and a fire-like mane. The horse is sitting on a table, and it appears to be a toy or a figurine. The fire-like mane gives the horse a unique and eye-catching appearance, making it stand out from other toys or figurines.\n"
          ]
        }
      ],
      "source": [
        "!cd LLaVA; python -m llava.eval.run_llava \\\n",
        "    --model-path liuhaotian/llava-llama-2-13b-chat-lightning-preview  \\\n",
        "    --image-file \"/content/LLaVA/images/llava_logo.png\" \\\n",
        "    --query \"USER: Can you describe this image?\\n<image-placeholder>\\nASSISTANT: \""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWrb-cshpn1u"
      },
      "source": [
        "## run with multiple images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4M7pFNccTeL",
        "outputId": "258e4ecd-20b0-4ef6-e069-0477adff1c2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-10-14 10:56:20,101] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-10-14 10:56:21.897100: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n",
            "Loading checkpoint shards: 100% 3/3 [00:20<00:00,  6.94s/it]\n",
            "image_files: ['https://llava-vl.github.io/static/images/view.jpg', '/content/LLaVA/images/llava_logo.png']\n",
            "image_file: https://llava-vl.github.io/static/images/view.jpg\n",
            "image_file: /content/LLaVA/images/llava_logo.png\n",
            "In the image, there is a small toy horse with a pair of glasses and a fire on its back. The horse is sitting on a wooden dock or a wooden platform, which is located near a body of water. The scene is set in a dark environment, which adds a dramatic and mysterious atmosphere to the image. The toy horse's unique appearance, with its glasses and fire, makes it an interesting and eye-catching subject.\n"
          ]
        }
      ],
      "source": [
        "# one-shot\n",
        "!cd LLaVA; python -m llava.eval.run_llava \\\n",
        "    --model-path liuhaotian/llava-llama-2-13b-chat-lightning-preview  \\\n",
        "    --image-file \"https://llava-vl.github.io/static/images/view.jpg,/content/LLaVA/images/llava_logo.png\" \\\n",
        "    --query \"USER: Can you describe the two images separately?\\nImage #1: <image-placeholder>\\nImage #2: <image-placeholder>\\nASSISTANT: \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTR64Dgc1wkw",
        "outputId": "789820d4-da47-4339-9c9c-04c399c36fce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-10-14 11:31:58,598] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-10-14 11:32:00.387118: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n",
            "Loading checkpoint shards: 100% 3/3 [00:20<00:00,  6.97s/it]\n",
            "In the image, there is a small toy or figurine of a horse with a fire on its back, standing on a wooden dock or pier. The scene is set during the day, and the water is calm and clear. The presence of the fire on the horse's back adds a unique and interesting element to the scene, making it visually striking and potentially symbolic. The toy horse's position on the dock suggests that it might be a decorative or artistic piece, possibly meant to evoke a sense of wonder or curiosity in those who view it.\n"
          ]
        }
      ],
      "source": [
        "# two-shots\n",
        "!cd LLaVA; python -m llava.eval.run_llava \\\n",
        "    --model-path liuhaotian/llava-llama-2-13b-chat-lightning-preview  \\\n",
        "    --image-file \"https://llava-vl.github.io/static/images/view.jpg,/content/LLaVA/images/llava_logo.png\" \\\n",
        "    --query \"USER: Can you describe this image?\\n<image-placeholder>\\nASSISTANT: In the image, there is a dock extending into a lake, with a mountain in the background. The dock is made of wood and appears to be a small pier or a docking area for boats. The scene is set during the day, and the water is calm and clear. The presence of the mountain in the background adds to the serene and picturesque atmosphere of the scene.\\nUSER: Can you describe this image?\\n<image-placeholder>\\nASSISTANT: \""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLaVA 1.5"
      ],
      "metadata": {
        "id": "5A_g3a0f707H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# one-shot\n",
        "!cd LLaVA; python -m llava.eval.run_llava \\\n",
        "    --model-path liuhaotian/llava-v1.5-13b  \\\n",
        "    --image-file \"https://llava-vl.github.io/static/images/view.jpg,/content/LLaVA/images/llava_logo.png\" \\\n",
        "    --query \"USER: Can you describe the two images separately?\\nImage #1: <image-placeholder>\\nImage #2: <image-placeholder>\\nASSISTANT: \"\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dizuw5jK735a",
        "outputId": "ecfef862-5c1c-4a57-f824-b43159f327ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-10-21 06:36:43,496] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-10-21 06:36:45.675521: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "(…)5-13b/resolve/main/tokenizer_config.json: 100% 749/749 [00:00<00:00, 4.18MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 56.9MB/s]\n",
            "(…)13b/resolve/main/special_tokens_map.json: 100% 438/438 [00:00<00:00, 2.69MB/s]\n",
            "(…)/llava-v1.5-13b/resolve/main/config.json: 100% 1.16k/1.16k [00:00<00:00, 5.46MB/s]\n",
            "(…)esolve/main/pytorch_model.bin.index.json: 100% 33.7k/33.7k [00:00<00:00, 30.8MB/s]\n",
            "Downloading shards:   0% 0/3 [00:00<?, ?it/s]\n",
            "pytorch_model-00001-of-00003.bin:   0% 0.00/9.95G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   0% 21.0M/9.95G [00:00<00:47, 208MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   1% 52.4M/9.95G [00:00<00:40, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   1% 83.9M/9.95G [00:00<00:38, 258MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   1% 115M/9.95G [00:00<00:37, 260MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   1% 147M/9.95G [00:00<00:42, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   2% 178M/9.95G [00:00<00:45, 214MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   2% 210M/9.95G [00:00<00:45, 215MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   3% 252M/9.95G [00:01<00:39, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   3% 283M/9.95G [00:01<00:38, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   3% 315M/9.95G [00:01<00:36, 267MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   3% 346M/9.95G [00:01<00:37, 257MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   4% 377M/9.95G [00:01<00:40, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   4% 409M/9.95G [00:01<00:40, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   4% 440M/9.95G [00:01<00:42, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   5% 472M/9.95G [00:02<00:45, 206MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   5% 503M/9.95G [00:02<00:44, 214MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   5% 535M/9.95G [00:02<00:42, 220MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   6% 566M/9.95G [00:02<00:39, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   6% 608M/9.95G [00:02<00:36, 257MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   6% 640M/9.95G [00:02<00:37, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   7% 682M/9.95G [00:02<00:33, 275MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   7% 713M/9.95G [00:02<00:34, 269MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   7% 744M/9.95G [00:03<00:35, 260MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   8% 776M/9.95G [00:03<00:37, 245MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   8% 807M/9.95G [00:03<00:37, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   8% 839M/9.95G [00:03<00:35, 259MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   9% 881M/9.95G [00:03<00:32, 278MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   9% 912M/9.95G [00:03<00:33, 271MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  10% 965M/9.95G [00:03<00:28, 316MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  10% 1.01G/9.95G [00:04<00:31, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  11% 1.05G/9.95G [00:04<00:29, 305MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  11% 1.09G/9.95G [00:04<00:26, 330MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  11% 1.13G/9.95G [00:04<00:27, 319MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  12% 1.17G/9.95G [00:04<00:34, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  12% 1.21G/9.95G [00:04<00:34, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  12% 1.24G/9.95G [00:04<00:37, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  13% 1.27G/9.95G [00:05<00:40, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  13% 1.30G/9.95G [00:05<00:38, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  13% 1.33G/9.95G [00:05<00:38, 221MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  14% 1.37G/9.95G [00:05<00:36, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  14% 1.41G/9.95G [00:05<00:37, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  15% 1.45G/9.95G [00:05<00:32, 265MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  15% 1.48G/9.95G [00:05<00:31, 271MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  15% 1.51G/9.95G [00:05<00:30, 280MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  16% 1.55G/9.95G [00:06<00:27, 310MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  16% 1.59G/9.95G [00:06<00:24, 338MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  16% 1.64G/9.95G [00:06<00:25, 329MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  17% 1.68G/9.95G [00:06<00:25, 328MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  17% 1.72G/9.95G [00:06<00:30, 269MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  18% 1.75G/9.95G [00:06<00:31, 258MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  18% 1.78G/9.95G [00:06<00:31, 263MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  18% 1.82G/9.95G [00:07<00:28, 284MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  19% 1.86G/9.95G [00:07<00:29, 270MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  19% 1.89G/9.95G [00:07<00:28, 281MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  19% 1.92G/9.95G [00:07<00:30, 262MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  20% 1.95G/9.95G [00:07<00:29, 272MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  20% 1.98G/9.95G [00:07<00:30, 265MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  20% 2.01G/9.95G [00:07<00:33, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  21% 2.04G/9.95G [00:07<00:31, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  21% 2.09G/9.95G [00:08<00:29, 263MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  21% 2.12G/9.95G [00:08<00:30, 259MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  22% 2.15G/9.95G [00:08<00:34, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  22% 2.18G/9.95G [00:08<00:31, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  22% 2.21G/9.95G [00:08<00:30, 256MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  23% 2.25G/9.95G [00:08<00:27, 277MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  23% 2.29G/9.95G [00:08<00:29, 257MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  23% 2.33G/9.95G [00:08<00:27, 277MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  24% 2.36G/9.95G [00:09<00:27, 274MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  24% 2.39G/9.95G [00:09<00:27, 276MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  24% 2.43G/9.95G [00:09<00:25, 293MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  25% 2.46G/9.95G [00:09<00:25, 298MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  25% 2.50G/9.95G [00:09<00:25, 288MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  26% 2.54G/9.95G [00:09<00:23, 317MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  26% 2.58G/9.95G [00:09<00:24, 300MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  26% 2.61G/9.95G [00:09<00:25, 293MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  27% 2.64G/9.95G [00:10<00:31, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  27% 2.67G/9.95G [00:10<00:30, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  27% 2.71G/9.95G [00:10<00:32, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  28% 2.74G/9.95G [00:10<00:31, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  28% 2.77G/9.95G [00:10<00:32, 220MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  28% 2.80G/9.95G [00:10<00:32, 220MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  29% 2.84G/9.95G [00:10<00:28, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  29% 2.87G/9.95G [00:11<00:26, 264MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  29% 2.90G/9.95G [00:11<00:30, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  30% 2.94G/9.95G [00:11<00:29, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  30% 2.97G/9.95G [00:11<00:31, 221MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  30% 3.00G/9.95G [00:11<00:31, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  30% 3.03G/9.95G [00:11<00:39, 175MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  31% 3.06G/9.95G [00:12<00:34, 199MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  31% 3.09G/9.95G [00:12<00:32, 211MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  31% 3.12G/9.95G [00:12<00:30, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  32% 3.16G/9.95G [00:12<00:29, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  32% 3.20G/9.95G [00:12<00:25, 265MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  32% 3.23G/9.95G [00:12<00:27, 249MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  33% 3.26G/9.95G [00:12<00:25, 264MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  33% 3.30G/9.95G [00:12<00:23, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  34% 3.34G/9.95G [00:13<00:22, 293MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  34% 3.38G/9.95G [00:13<00:23, 277MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  34% 3.41G/9.95G [00:13<00:25, 259MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  35% 3.44G/9.95G [00:13<00:25, 257MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  35% 3.47G/9.95G [00:13<00:28, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  35% 3.50G/9.95G [00:13<00:28, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  36% 3.53G/9.95G [00:13<00:29, 218MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  36% 3.57G/9.95G [00:14<00:36, 174MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  36% 3.60G/9.95G [00:14<00:32, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  37% 3.64G/9.95G [00:14<00:26, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  37% 3.67G/9.95G [00:14<00:25, 245MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  37% 3.70G/9.95G [00:14<00:25, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  38% 3.74G/9.95G [00:14<00:22, 272MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  38% 3.77G/9.95G [00:14<00:22, 274MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  38% 3.82G/9.95G [00:15<00:20, 304MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  39% 3.86G/9.95G [00:15<00:20, 293MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  39% 3.89G/9.95G [00:15<00:24, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  39% 3.92G/9.95G [00:15<00:23, 253MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  40% 3.95G/9.95G [00:15<00:23, 253MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  40% 3.98G/9.95G [00:15<00:22, 261MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  40% 4.02G/9.95G [00:15<00:23, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  41% 4.05G/9.95G [00:15<00:23, 248MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  41% 4.08G/9.95G [00:16<00:22, 262MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  41% 4.11G/9.95G [00:16<00:23, 249MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  42% 4.14G/9.95G [00:16<00:22, 264MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  42% 4.17G/9.95G [00:16<00:21, 270MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  42% 4.20G/9.95G [00:16<00:23, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  43% 4.24G/9.95G [00:16<00:24, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  43% 4.27G/9.95G [00:16<00:22, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  43% 4.31G/9.95G [00:16<00:20, 281MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  44% 4.35G/9.95G [00:17<00:18, 300MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  44% 4.38G/9.95G [00:17<00:18, 296MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  44% 4.41G/9.95G [00:17<00:19, 287MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  45% 4.45G/9.95G [00:17<00:19, 283MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  45% 4.48G/9.95G [00:17<00:22, 248MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  45% 4.51G/9.95G [00:17<00:25, 212MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  46% 4.54G/9.95G [00:17<00:25, 210MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  46% 4.57G/9.95G [00:18<00:25, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  46% 4.60G/9.95G [00:18<00:24, 220MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  47% 4.63G/9.95G [00:18<00:23, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  47% 4.68G/9.95G [00:18<00:21, 250MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  47% 4.72G/9.95G [00:18<00:20, 259MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  48% 4.75G/9.95G [00:18<00:19, 262MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  48% 4.78G/9.95G [00:18<00:19, 270MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  48% 4.81G/9.95G [00:18<00:18, 274MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  49% 4.84G/9.95G [00:19<00:18, 275MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  49% 4.89G/9.95G [00:19<00:16, 302MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  49% 4.92G/9.95G [00:19<00:17, 291MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  50% 4.95G/9.95G [00:19<00:17, 293MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  50% 4.98G/9.95G [00:19<00:20, 244MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  50% 5.01G/9.95G [00:19<00:21, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  51% 5.04G/9.95G [00:19<00:19, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  51% 5.08G/9.95G [00:20<00:19, 248MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  51% 5.11G/9.95G [00:20<00:20, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  52% 5.14G/9.95G [00:20<00:18, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  52% 5.17G/9.95G [00:20<00:19, 249MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  52% 5.20G/9.95G [00:20<00:22, 211MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  53% 5.23G/9.95G [00:20<00:20, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  53% 5.27G/9.95G [00:20<00:17, 266MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  53% 5.31G/9.95G [00:20<00:17, 258MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  54% 5.35G/9.95G [00:21<00:16, 275MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  54% 5.38G/9.95G [00:21<00:16, 272MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  54% 5.41G/9.95G [00:21<00:16, 272MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  55% 5.44G/9.95G [00:21<00:16, 278MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  55% 5.48G/9.95G [00:21<00:15, 297MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  55% 5.52G/9.95G [00:21<00:15, 290MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  56% 5.56G/9.95G [00:21<00:14, 311MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  56% 5.60G/9.95G [00:21<00:13, 315MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  57% 5.64G/9.95G [00:22<00:13, 319MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  57% 5.68G/9.95G [00:22<00:13, 326MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  58% 5.73G/9.95G [00:22<00:13, 309MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  58% 5.76G/9.95G [00:22<00:15, 272MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  58% 5.80G/9.95G [00:22<00:13, 301MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  59% 5.84G/9.95G [00:22<00:13, 302MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  59% 5.88G/9.95G [00:22<00:12, 313MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  60% 5.92G/9.95G [00:23<00:14, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  60% 5.96G/9.95G [00:23<00:14, 270MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  60% 5.99G/9.95G [00:23<00:14, 273MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  60% 6.02G/9.95G [00:23<00:14, 265MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  61% 6.06G/9.95G [00:23<00:13, 294MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  61% 6.10G/9.95G [00:23<00:13, 292MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  62% 6.13G/9.95G [00:23<00:12, 293MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  62% 6.17G/9.95G [00:23<00:13, 277MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  62% 6.20G/9.95G [00:24<00:16, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  63% 6.23G/9.95G [00:24<00:15, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  63% 6.26G/9.95G [00:24<00:20, 180MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  63% 6.30G/9.95G [00:24<00:16, 217MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  64% 6.33G/9.95G [00:24<00:16, 220MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  64% 6.36G/9.95G [00:24<00:15, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  64% 6.40G/9.95G [00:25<00:19, 187MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  65% 6.43G/9.95G [00:25<00:18, 191MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  65% 6.46G/9.95G [00:25<00:17, 201MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  65% 6.49G/9.95G [00:25<00:15, 221MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  66% 6.52G/9.95G [00:25<00:14, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  66% 6.55G/9.95G [00:25<00:13, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  66% 6.59G/9.95G [00:25<00:13, 248MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  67% 6.62G/9.95G [00:25<00:13, 250MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  67% 6.65G/9.95G [00:26<00:14, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  67% 6.68G/9.95G [00:26<00:14, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  68% 6.72G/9.95G [00:26<00:12, 250MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  68% 6.75G/9.95G [00:26<00:12, 253MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  68% 6.78G/9.95G [00:26<00:12, 263MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  69% 6.83G/9.95G [00:26<00:11, 282MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  69% 6.86G/9.95G [00:26<00:11, 271MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  69% 6.89G/9.95G [00:27<00:11, 265MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  70% 6.92G/9.95G [00:27<00:11, 268MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  70% 6.95G/9.95G [00:27<00:10, 275MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  70% 6.99G/9.95G [00:27<00:09, 296MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  71% 7.03G/9.95G [00:27<00:17, 171MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  71% 7.06G/9.95G [00:27<00:14, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  71% 7.10G/9.95G [00:27<00:12, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  72% 7.14G/9.95G [00:28<00:10, 258MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  72% 7.18G/9.95G [00:28<00:09, 291MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  73% 7.22G/9.95G [00:28<00:09, 283MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  73% 7.26G/9.95G [00:28<00:09, 276MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  73% 7.29G/9.95G [00:28<00:10, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  74% 7.33G/9.95G [00:28<00:09, 268MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  74% 7.36G/9.95G [00:28<00:10, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  74% 7.39G/9.95G [00:29<00:10, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  75% 7.43G/9.95G [00:29<00:09, 271MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  75% 7.47G/9.95G [00:29<00:08, 279MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  75% 7.51G/9.95G [00:29<00:08, 290MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  76% 7.54G/9.95G [00:29<00:09, 268MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  76% 7.58G/9.95G [00:29<00:08, 290MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  77% 7.62G/9.95G [00:29<00:07, 321MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  77% 7.67G/9.95G [00:29<00:07, 307MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  77% 7.71G/9.95G [00:30<00:07, 299MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  78% 7.74G/9.95G [00:30<00:07, 292MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  78% 7.78G/9.95G [00:30<00:07, 308MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  79% 7.82G/9.95G [00:30<00:06, 313MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  79% 7.86G/9.95G [00:30<00:06, 321MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  79% 7.91G/9.95G [00:30<00:06, 306MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  80% 7.95G/9.95G [00:30<00:06, 313MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  80% 7.99G/9.95G [00:30<00:06, 314MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  81% 8.03G/9.95G [00:31<00:06, 283MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  81% 8.07G/9.95G [00:31<00:06, 305MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  81% 8.11G/9.95G [00:31<00:06, 290MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  82% 8.15G/9.95G [00:31<00:05, 321MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  82% 8.19G/9.95G [00:31<00:05, 323MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  83% 8.23G/9.95G [00:31<00:05, 299MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  83% 8.26G/9.95G [00:31<00:05, 283MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  83% 8.30G/9.95G [00:32<00:05, 303MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  84% 8.34G/9.95G [00:32<00:05, 305MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  84% 8.37G/9.95G [00:32<00:05, 275MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  84% 8.40G/9.95G [00:32<00:05, 276MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  85% 8.43G/9.95G [00:32<00:05, 269MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  85% 8.46G/9.95G [00:32<00:05, 280MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  85% 8.50G/9.95G [00:32<00:05, 265MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  86% 8.54G/9.95G [00:32<00:06, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  86% 8.57G/9.95G [00:33<00:06, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  86% 8.60G/9.95G [00:33<00:05, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  87% 8.63G/9.95G [00:33<00:05, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  87% 8.67G/9.95G [00:33<00:04, 266MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  87% 8.70G/9.95G [00:33<00:06, 204MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  88% 8.75G/9.95G [00:33<00:05, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  88% 8.79G/9.95G [00:34<00:04, 268MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  89% 8.83G/9.95G [00:34<00:03, 288MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  89% 8.86G/9.95G [00:34<00:03, 272MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  89% 8.90G/9.95G [00:34<00:03, 291MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  90% 8.93G/9.95G [00:34<00:04, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  90% 8.98G/9.95G [00:34<00:03, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  91% 9.03G/9.95G [00:34<00:03, 298MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  91% 9.07G/9.95G [00:35<00:02, 297MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  92% 9.11G/9.95G [00:35<00:03, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  92% 9.14G/9.95G [00:35<00:03, 256MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  92% 9.18G/9.95G [00:35<00:03, 257MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  93% 9.22G/9.95G [00:35<00:02, 292MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  93% 9.26G/9.95G [00:35<00:02, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  93% 9.29G/9.95G [00:35<00:02, 291MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  94% 9.34G/9.95G [00:35<00:01, 326MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  94% 9.38G/9.95G [00:36<00:01, 301MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  95% 9.43G/9.95G [00:36<00:01, 316MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  95% 9.47G/9.95G [00:36<00:01, 313MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  96% 9.51G/9.95G [00:36<00:01, 328MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  96% 9.55G/9.95G [00:36<00:01, 287MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  96% 9.59G/9.95G [00:36<00:01, 295MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  97% 9.64G/9.95G [00:36<00:01, 306MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  97% 9.68G/9.95G [00:37<00:00, 319MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  98% 9.72G/9.95G [00:37<00:00, 322MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  98% 9.76G/9.95G [00:37<00:00, 318MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  99% 9.80G/9.95G [00:37<00:00, 275MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  99% 9.84G/9.95G [00:37<00:00, 262MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  99% 9.88G/9.95G [00:37<00:00, 256MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin: 100% 9.91G/9.95G [00:38<00:00, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin: 100% 9.95G/9.95G [00:38<00:00, 260MB/s]\n",
            "Downloading shards:  33% 1/3 [00:39<01:19, 39.51s/it]\n",
            "pytorch_model-00002-of-00003.bin:   0% 0.00/9.90G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   0% 21.0M/9.90G [00:00<00:49, 200MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   1% 52.4M/9.90G [00:00<00:39, 252MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   1% 83.9M/9.90G [00:00<00:37, 263MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   1% 115M/9.90G [00:00<00:38, 252MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   1% 147M/9.90G [00:00<00:38, 255MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   2% 178M/9.90G [00:00<00:36, 267MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   2% 210M/9.90G [00:00<00:41, 235MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   2% 241M/9.90G [00:00<00:37, 255MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   3% 273M/9.90G [00:01<00:50, 190MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   3% 315M/9.90G [00:01<00:40, 234MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   3% 346M/9.90G [00:01<00:39, 245MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   4% 377M/9.90G [00:01<00:40, 236MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   4% 419M/9.90G [00:01<00:35, 264MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   5% 451M/9.90G [00:01<00:35, 265MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   5% 482M/9.90G [00:01<00:34, 271MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   5% 514M/9.90G [00:02<00:34, 271MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   6% 545M/9.90G [00:02<00:38, 242MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   6% 587M/9.90G [00:02<00:34, 270MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   6% 619M/9.90G [00:02<00:35, 259MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   7% 650M/9.90G [00:02<00:34, 267MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   7% 682M/9.90G [00:02<00:34, 265MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   7% 713M/9.90G [00:02<00:36, 251MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   8% 755M/9.90G [00:02<00:33, 277MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   8% 786M/9.90G [00:03<00:33, 269MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   8% 818M/9.90G [00:03<00:37, 245MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   9% 870M/9.90G [00:03<00:30, 297MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   9% 912M/9.90G [00:03<00:29, 300MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  10% 954M/9.90G [00:03<00:28, 310MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  10% 986M/9.90G [00:03<00:33, 270MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  10% 1.02G/9.90G [00:03<00:34, 254MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  11% 1.06G/9.90G [00:04<00:32, 274MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  11% 1.09G/9.90G [00:04<00:31, 280MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  11% 1.13G/9.90G [00:04<00:28, 304MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  12% 1.16G/9.90G [00:04<00:29, 294MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  12% 1.20G/9.90G [00:04<00:29, 291MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  12% 1.24G/9.90G [00:04<00:29, 293MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  13% 1.28G/9.90G [00:04<00:27, 319MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  13% 1.32G/9.90G [00:04<00:25, 336MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  14% 1.36G/9.90G [00:05<00:28, 299MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  14% 1.39G/9.90G [00:05<00:29, 284MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  14% 1.43G/9.90G [00:05<00:43, 193MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  15% 1.48G/9.90G [00:05<00:34, 242MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  15% 1.51G/9.90G [00:05<00:33, 248MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  16% 1.55G/9.90G [00:05<00:30, 274MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  16% 1.59G/9.90G [00:05<00:27, 302MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  17% 1.64G/9.90G [00:06<00:27, 305MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  17% 1.68G/9.90G [00:06<00:28, 288MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  17% 1.72G/9.90G [00:06<00:26, 310MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  18% 1.76G/9.90G [00:06<00:26, 309MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  18% 1.80G/9.90G [00:06<00:28, 287MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  19% 1.84G/9.90G [00:06<00:29, 274MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  19% 1.88G/9.90G [00:06<00:26, 298MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  19% 1.92G/9.90G [00:07<00:25, 319MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  20% 1.96G/9.90G [00:07<00:23, 333MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  20% 2.00G/9.90G [00:07<00:23, 334MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  21% 2.04G/9.90G [00:07<00:22, 349MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  21% 2.09G/9.90G [00:07<00:22, 343MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  21% 2.13G/9.90G [00:07<00:24, 320MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  22% 2.17G/9.90G [00:07<00:26, 293MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  22% 2.21G/9.90G [00:07<00:26, 292MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  23% 2.24G/9.90G [00:08<00:28, 270MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  23% 2.29G/9.90G [00:08<00:25, 295MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  24% 2.33G/9.90G [00:08<00:25, 302MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  24% 2.37G/9.90G [00:08<00:23, 324MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  24% 2.41G/9.90G [00:08<00:24, 308MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  25% 2.46G/9.90G [00:08<00:22, 336MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  25% 2.51G/9.90G [00:08<00:22, 326MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  26% 2.55G/9.90G [00:09<00:22, 324MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  26% 2.59G/9.90G [00:09<00:21, 339MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  27% 2.63G/9.90G [00:09<00:23, 315MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  27% 2.67G/9.90G [00:09<00:22, 323MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  27% 2.72G/9.90G [00:09<00:22, 322MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  28% 2.76G/9.90G [00:09<00:22, 313MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  28% 2.80G/9.90G [00:09<00:22, 318MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  29% 2.84G/9.90G [00:09<00:22, 311MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  29% 2.88G/9.90G [00:10<00:23, 302MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  29% 2.92G/9.90G [00:10<00:24, 287MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  30% 2.95G/9.90G [00:10<00:24, 287MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  30% 2.99G/9.90G [00:10<00:22, 312MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  30% 3.02G/9.90G [00:10<00:26, 259MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  31% 3.05G/9.90G [00:10<00:26, 260MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  31% 3.09G/9.90G [00:10<00:23, 290MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  32% 3.12G/9.90G [00:10<00:23, 286MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  32% 3.16G/9.90G [00:11<00:23, 283MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  32% 3.19G/9.90G [00:11<00:37, 177MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  33% 3.22G/9.90G [00:11<00:35, 189MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  33% 3.25G/9.90G [00:11<00:32, 205MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  33% 3.28G/9.90G [00:11<00:31, 211MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  33% 3.31G/9.90G [00:11<00:30, 215MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  34% 3.34G/9.90G [00:12<00:29, 220MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  34% 3.39G/9.90G [00:12<00:26, 245MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  35% 3.42G/9.90G [00:12<00:25, 256MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  35% 3.45G/9.90G [00:12<00:27, 239MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  35% 3.48G/9.90G [00:12<00:26, 246MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  36% 3.52G/9.90G [00:12<00:22, 283MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  36% 3.55G/9.90G [00:12<00:24, 263MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  36% 3.59G/9.90G [00:13<00:25, 246MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  37% 3.62G/9.90G [00:13<00:26, 239MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  37% 3.65G/9.90G [00:13<00:27, 225MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  37% 3.68G/9.90G [00:13<00:27, 228MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  37% 3.71G/9.90G [00:13<00:26, 231MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  38% 3.74G/9.90G [00:13<00:28, 219MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  38% 3.77G/9.90G [00:13<00:27, 222MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  38% 3.81G/9.90G [00:14<00:27, 224MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  39% 3.84G/9.90G [00:14<00:25, 237MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  39% 3.87G/9.90G [00:14<00:30, 201MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  39% 3.90G/9.90G [00:14<00:28, 212MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  40% 3.93G/9.90G [00:14<00:28, 207MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  40% 3.96G/9.90G [00:14<00:29, 202MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  40% 3.98G/9.90G [00:14<00:32, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  41% 4.02G/9.90G [00:15<00:29, 201MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  41% 4.05G/9.90G [00:15<00:28, 207MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  41% 4.08G/9.90G [00:15<00:27, 212MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  42% 4.11G/9.90G [00:15<00:26, 215MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  42% 4.14G/9.90G [00:15<00:25, 223MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  42% 4.17G/9.90G [00:15<00:25, 223MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  42% 4.20G/9.90G [00:15<00:23, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  43% 4.24G/9.90G [00:16<00:23, 239MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  43% 4.27G/9.90G [00:16<00:22, 254MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  43% 4.30G/9.90G [00:16<00:21, 264MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  44% 4.33G/9.90G [00:16<00:22, 249MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  44% 4.36G/9.90G [00:16<00:21, 253MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  44% 4.39G/9.90G [00:16<00:21, 260MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  45% 4.44G/9.90G [00:16<00:20, 260MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  45% 4.47G/9.90G [00:16<00:20, 268MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  45% 4.50G/9.90G [00:17<00:20, 260MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  46% 4.53G/9.90G [00:17<00:20, 267MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  46% 4.56G/9.90G [00:17<00:20, 264MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  46% 4.59G/9.90G [00:17<00:19, 268MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  47% 4.62G/9.90G [00:17<00:22, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  47% 4.66G/9.90G [00:17<00:20, 253MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  47% 4.69G/9.90G [00:17<00:24, 210MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  48% 4.72G/9.90G [00:17<00:25, 206MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  48% 4.75G/9.90G [00:18<00:22, 228MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  48% 4.78G/9.90G [00:18<00:20, 246MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  49% 4.81G/9.90G [00:18<00:20, 253MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  49% 4.84G/9.90G [00:18<00:19, 262MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  49% 4.88G/9.90G [00:18<00:19, 255MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  50% 4.91G/9.90G [00:18<00:20, 242MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  50% 4.95G/9.90G [00:18<00:17, 283MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  50% 4.98G/9.90G [00:18<00:19, 247MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  51% 5.01G/9.90G [00:19<00:21, 223MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  51% 5.04G/9.90G [00:19<00:20, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  51% 5.08G/9.90G [00:19<00:19, 245MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  52% 5.11G/9.90G [00:19<00:21, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  52% 5.14G/9.90G [00:19<00:21, 222MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  52% 5.18G/9.90G [00:19<00:19, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  53% 5.21G/9.90G [00:19<00:19, 236MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  53% 5.24G/9.90G [00:20<00:19, 233MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  53% 5.27G/9.90G [00:20<00:19, 232MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  54% 5.32G/9.90G [00:20<00:17, 255MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  54% 5.35G/9.90G [00:20<00:17, 253MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  54% 5.38G/9.90G [00:20<00:18, 245MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  55% 5.41G/9.90G [00:20<00:20, 223MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  55% 5.44G/9.90G [00:20<00:19, 231MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  55% 5.47G/9.90G [00:21<00:19, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  56% 5.51G/9.90G [00:21<00:21, 208MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  56% 5.54G/9.90G [00:21<00:25, 173MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  56% 5.56G/9.90G [00:21<00:24, 176MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  57% 5.60G/9.90G [00:21<00:20, 213MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  57% 5.63G/9.90G [00:21<00:18, 233MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  57% 5.66G/9.90G [00:22<00:17, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  57% 5.69G/9.90G [00:22<00:16, 255MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  58% 5.73G/9.90G [00:22<00:21, 197MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  58% 5.76G/9.90G [00:22<00:18, 221MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  58% 5.79G/9.90G [00:22<00:18, 227MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  59% 5.82G/9.90G [00:22<00:17, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  59% 5.86G/9.90G [00:22<00:14, 270MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  60% 5.89G/9.90G [00:22<00:16, 245MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  60% 5.92G/9.90G [00:23<00:17, 231MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  60% 5.96G/9.90G [00:23<00:19, 203MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  60% 5.99G/9.90G [00:23<00:17, 218MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  61% 6.02G/9.90G [00:23<00:16, 234MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  61% 6.05G/9.90G [00:23<00:15, 253MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  62% 6.10G/9.90G [00:23<00:13, 291MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  62% 6.13G/9.90G [00:23<00:13, 286MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  62% 6.18G/9.90G [00:24<00:12, 296MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  63% 6.21G/9.90G [00:24<00:12, 289MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  63% 6.25G/9.90G [00:24<00:12, 299MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  63% 6.28G/9.90G [00:24<00:11, 302MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  64% 6.32G/9.90G [00:24<00:11, 313MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  64% 6.36G/9.90G [00:24<00:11, 316MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  65% 6.41G/9.90G [00:24<00:11, 316MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  65% 6.45G/9.90G [00:24<00:11, 311MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  66% 6.49G/9.90G [00:25<00:11, 306MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  66% 6.52G/9.90G [00:25<00:12, 281MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  66% 6.55G/9.90G [00:25<00:11, 285MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  66% 6.59G/9.90G [00:25<00:11, 289MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  67% 6.63G/9.90G [00:25<00:10, 310MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  67% 6.66G/9.90G [00:25<00:10, 296MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  68% 6.69G/9.90G [00:25<00:11, 278MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  68% 6.72G/9.90G [00:25<00:11, 276MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  68% 6.76G/9.90G [00:26<00:10, 296MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  69% 6.81G/9.90G [00:26<00:09, 322MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  69% 6.85G/9.90G [00:26<00:09, 335MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  70% 6.89G/9.90G [00:26<00:08, 342MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  70% 6.93G/9.90G [00:26<00:08, 354MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  70% 6.97G/9.90G [00:26<00:08, 358MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  71% 7.01G/9.90G [00:26<00:07, 370MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  71% 7.06G/9.90G [00:26<00:08, 335MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  72% 7.10G/9.90G [00:27<00:09, 310MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  72% 7.14G/9.90G [00:27<00:09, 306MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  72% 7.17G/9.90G [00:27<00:09, 293MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  73% 7.20G/9.90G [00:27<00:09, 288MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  73% 7.26G/9.90G [00:27<00:07, 332MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  74% 7.30G/9.90G [00:27<00:08, 312MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  74% 7.34G/9.90G [00:27<00:08, 303MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  74% 7.37G/9.90G [00:27<00:08, 287MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  75% 7.40G/9.90G [00:28<00:09, 277MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  75% 7.43G/9.90G [00:28<00:09, 274MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  75% 7.47G/9.90G [00:28<00:08, 272MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  76% 7.50G/9.90G [00:28<00:08, 269MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  76% 7.54G/9.90G [00:28<00:08, 293MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  76% 7.57G/9.90G [00:28<00:09, 256MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  77% 7.60G/9.90G [00:28<00:08, 257MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  77% 7.63G/9.90G [00:28<00:08, 258MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  77% 7.67G/9.90G [00:29<00:09, 240MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  78% 7.70G/9.90G [00:29<00:10, 217MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  78% 7.73G/9.90G [00:29<00:09, 235MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  78% 7.76G/9.90G [00:29<00:09, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  79% 7.79G/9.90G [00:29<00:08, 256MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  79% 7.83G/9.90G [00:29<00:07, 294MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  79% 7.86G/9.90G [00:29<00:07, 284MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  80% 7.90G/9.90G [00:29<00:07, 261MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  80% 7.93G/9.90G [00:30<00:07, 271MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  80% 7.97G/9.90G [00:30<00:06, 284MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  81% 8.01G/9.90G [00:30<00:06, 292MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  81% 8.04G/9.90G [00:30<00:06, 272MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  82% 8.07G/9.90G [00:30<00:07, 251MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  82% 8.11G/9.90G [00:30<00:07, 239MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  82% 8.14G/9.90G [00:30<00:08, 217MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  82% 8.17G/9.90G [00:31<00:07, 227MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  83% 8.20G/9.90G [00:31<00:06, 246MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  83% 8.24G/9.90G [00:31<00:06, 259MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  84% 8.27G/9.90G [00:31<00:06, 249MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  84% 8.30G/9.90G [00:31<00:06, 255MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  84% 8.34G/9.90G [00:31<00:08, 185MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  84% 8.37G/9.90G [00:31<00:07, 210MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  85% 8.41G/9.90G [00:32<00:06, 239MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  85% 8.45G/9.90G [00:32<00:05, 251MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  86% 8.49G/9.90G [00:32<00:05, 272MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  86% 8.52G/9.90G [00:32<00:05, 269MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  86% 8.56G/9.90G [00:32<00:05, 246MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  87% 8.59G/9.90G [00:32<00:05, 248MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  87% 8.62G/9.90G [00:32<00:05, 254MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  87% 8.65G/9.90G [00:33<00:04, 267MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  88% 8.68G/9.90G [00:33<00:04, 261MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  88% 8.71G/9.90G [00:33<00:04, 264MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  88% 8.75G/9.90G [00:33<00:04, 241MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  89% 8.78G/9.90G [00:33<00:04, 240MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  89% 8.81G/9.90G [00:33<00:04, 245MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  89% 8.84G/9.90G [00:33<00:04, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  90% 8.87G/9.90G [00:33<00:04, 247MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  90% 8.90G/9.90G [00:34<00:04, 239MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  90% 8.93G/9.90G [00:34<00:04, 236MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  91% 8.98G/9.90G [00:34<00:03, 251MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  91% 9.01G/9.90G [00:34<00:03, 254MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  91% 9.05G/9.90G [00:34<00:03, 281MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  92% 9.09G/9.90G [00:34<00:02, 310MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  92% 9.13G/9.90G [00:34<00:02, 290MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  93% 9.16G/9.90G [00:34<00:02, 279MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  93% 9.21G/9.90G [00:35<00:02, 274MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  93% 9.24G/9.90G [00:35<00:02, 261MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  94% 9.27G/9.90G [00:35<00:02, 271MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  94% 9.31G/9.90G [00:35<00:02, 281MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  94% 9.35G/9.90G [00:35<00:01, 288MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  95% 9.40G/9.90G [00:35<00:01, 297MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  95% 9.43G/9.90G [00:35<00:01, 293MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  95% 9.46G/9.90G [00:36<00:01, 276MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  96% 9.49G/9.90G [00:36<00:01, 252MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  96% 9.52G/9.90G [00:36<00:01, 251MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  96% 9.55G/9.90G [00:36<00:01, 255MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  97% 9.58G/9.90G [00:36<00:01, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  97% 9.62G/9.90G [00:36<00:01, 239MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  97% 9.65G/9.90G [00:36<00:01, 218MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  98% 9.68G/9.90G [00:37<00:00, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  98% 9.72G/9.90G [00:37<00:00, 268MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  98% 9.75G/9.90G [00:37<00:00, 269MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  99% 9.79G/9.90G [00:37<00:00, 295MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  99% 9.83G/9.90G [00:37<00:00, 287MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin: 100% 9.90G/9.90G [00:37<00:00, 263MB/s]\n",
            "Downloading shards:  67% 2/3 [01:18<00:39, 39.16s/it]\n",
            "pytorch_model-00003-of-00003.bin:   0% 0.00/6.24G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   1% 31.5M/6.24G [00:00<00:25, 243MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   1% 62.9M/6.24G [00:00<00:24, 254MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   2% 94.4M/6.24G [00:00<00:26, 233MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   2% 126M/6.24G [00:00<00:24, 247MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   3% 168M/6.24G [00:00<00:22, 270MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   3% 210M/6.24G [00:00<00:19, 305MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   4% 252M/6.24G [00:00<00:19, 315MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   5% 294M/6.24G [00:01<00:18, 320MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   5% 336M/6.24G [00:01<00:17, 329MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   6% 377M/6.24G [00:01<00:17, 326MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   7% 419M/6.24G [00:01<00:19, 293MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   7% 451M/6.24G [00:01<00:19, 297MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   8% 482M/6.24G [00:01<00:19, 291MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   8% 514M/6.24G [00:01<00:19, 291MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   9% 545M/6.24G [00:01<00:22, 251MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   9% 577M/6.24G [00:02<00:23, 246MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  10% 608M/6.24G [00:02<00:23, 240MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  10% 640M/6.24G [00:02<00:25, 217MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  11% 671M/6.24G [00:02<00:26, 212MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  11% 703M/6.24G [00:02<00:28, 193MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  12% 724M/6.24G [00:02<00:31, 178MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  12% 755M/6.24G [00:02<00:26, 206MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  13% 786M/6.24G [00:03<00:27, 196MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  13% 818M/6.24G [00:03<00:25, 212MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  14% 860M/6.24G [00:03<00:21, 253MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  14% 891M/6.24G [00:03<00:22, 239MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  15% 923M/6.24G [00:03<00:21, 250MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  15% 954M/6.24G [00:03<00:20, 257MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  16% 996M/6.24G [00:03<00:18, 284MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  17% 1.04G/6.24G [00:04<00:17, 304MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  17% 1.07G/6.24G [00:04<00:17, 304MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  18% 1.10G/6.24G [00:04<00:20, 254MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  18% 1.14G/6.24G [00:04<00:17, 285MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  19% 1.17G/6.24G [00:04<00:17, 287MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  19% 1.22G/6.24G [00:04<00:16, 301MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  20% 1.25G/6.24G [00:04<00:16, 295MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  21% 1.29G/6.24G [00:04<00:16, 302MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  21% 1.33G/6.24G [00:05<00:16, 290MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  22% 1.36G/6.24G [00:05<00:17, 283MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  22% 1.39G/6.24G [00:05<00:17, 274MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  23% 1.43G/6.24G [00:05<00:19, 253MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  23% 1.46G/6.24G [00:05<00:18, 253MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  24% 1.51G/6.24G [00:05<00:15, 304MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  25% 1.54G/6.24G [00:05<00:15, 306MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  25% 1.57G/6.24G [00:05<00:16, 283MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  26% 1.60G/6.24G [00:06<00:16, 289MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  26% 1.65G/6.24G [00:06<00:14, 310MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  27% 1.68G/6.24G [00:06<00:15, 297MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  27% 1.71G/6.24G [00:06<00:15, 289MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  28% 1.74G/6.24G [00:06<00:16, 273MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  28% 1.77G/6.24G [00:06<00:16, 268MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  29% 1.80G/6.24G [00:06<00:16, 264MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  29% 1.84G/6.24G [00:06<00:16, 261MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  30% 1.88G/6.24G [00:06<00:15, 286MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  31% 1.91G/6.24G [00:07<00:15, 285MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  31% 1.95G/6.24G [00:07<00:14, 286MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  32% 1.98G/6.24G [00:07<00:16, 266MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  32% 2.01G/6.24G [00:07<00:15, 267MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  33% 2.06G/6.24G [00:07<00:14, 284MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  34% 2.11G/6.24G [00:07<00:18, 220MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  34% 2.15G/6.24G [00:08<00:16, 252MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  35% 2.18G/6.24G [00:08<00:16, 243MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  35% 2.21G/6.24G [00:08<00:17, 228MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  36% 2.24G/6.24G [00:08<00:16, 237MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  37% 2.29G/6.24G [00:08<00:15, 249MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  37% 2.32G/6.24G [00:08<00:18, 217MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  38% 2.35G/6.24G [00:09<00:22, 175MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  38% 2.39G/6.24G [00:09<00:18, 207MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  39% 2.42G/6.24G [00:09<00:18, 212MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  39% 2.45G/6.24G [00:09<00:16, 225MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  40% 2.49G/6.24G [00:09<00:16, 231MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  40% 2.52G/6.24G [00:09<00:15, 234MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  41% 2.55G/6.24G [00:09<00:16, 220MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  41% 2.58G/6.24G [00:10<00:15, 231MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  42% 2.61G/6.24G [00:10<00:19, 187MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  42% 2.63G/6.24G [00:10<00:20, 172MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  43% 2.66G/6.24G [00:10<00:18, 193MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  43% 2.68G/6.24G [00:10<00:24, 144MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  44% 2.72G/6.24G [00:10<00:20, 171MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  44% 2.75G/6.24G [00:11<00:19, 178MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  45% 2.78G/6.24G [00:11<00:17, 193MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  45% 2.81G/6.24G [00:11<00:20, 169MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  46% 2.84G/6.24G [00:11<00:18, 181MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  46% 2.87G/6.24G [00:11<00:17, 197MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  47% 2.90G/6.24G [00:11<00:16, 204MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  47% 2.95G/6.24G [00:12<00:13, 242MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  48% 2.98G/6.24G [00:12<00:13, 241MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  48% 3.01G/6.24G [00:12<00:12, 249MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  49% 3.05G/6.24G [00:12<00:11, 277MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  50% 3.09G/6.24G [00:12<00:10, 295MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  50% 3.12G/6.24G [00:12<00:11, 270MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  51% 3.16G/6.24G [00:12<00:11, 257MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  51% 3.19G/6.24G [00:12<00:12, 251MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  52% 3.22G/6.24G [00:13<00:13, 218MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  52% 3.25G/6.24G [00:13<00:12, 233MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  53% 3.28G/6.24G [00:13<00:13, 219MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  53% 3.32G/6.24G [00:13<00:11, 248MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  54% 3.36G/6.24G [00:13<00:13, 218MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  54% 3.39G/6.24G [00:13<00:12, 222MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  55% 3.42G/6.24G [00:13<00:12, 231MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  55% 3.46G/6.24G [00:14<00:10, 266MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  56% 3.50G/6.24G [00:14<00:09, 290MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  57% 3.53G/6.24G [00:14<00:09, 274MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  57% 3.57G/6.24G [00:14<00:09, 279MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  58% 3.61G/6.24G [00:14<00:08, 306MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  58% 3.64G/6.24G [00:14<00:09, 277MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  59% 3.67G/6.24G [00:14<00:09, 273MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  59% 3.70G/6.24G [00:14<00:09, 270MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  60% 3.73G/6.24G [00:15<00:09, 264MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  60% 3.77G/6.24G [00:15<00:08, 284MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  61% 3.81G/6.24G [00:15<00:09, 269MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  62% 3.85G/6.24G [00:15<00:08, 299MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  62% 3.89G/6.24G [00:15<00:07, 323MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  63% 3.93G/6.24G [00:15<00:07, 318MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  64% 3.97G/6.24G [00:15<00:07, 287MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  64% 4.01G/6.24G [00:16<00:15, 148MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  65% 4.04G/6.24G [00:16<00:13, 168MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  65% 4.07G/6.24G [00:16<00:15, 140MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  66% 4.10G/6.24G [00:16<00:13, 163MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  66% 4.14G/6.24G [00:17<00:11, 189MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  67% 4.17G/6.24G [00:17<00:10, 204MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  67% 4.20G/6.24G [00:17<00:10, 199MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  68% 4.24G/6.24G [00:17<00:13, 147MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  68% 4.26G/6.24G [00:17<00:16, 123MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  69% 4.28G/6.24G [00:18<00:14, 132MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  69% 4.32G/6.24G [00:18<00:11, 171MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  70% 4.34G/6.24G [00:18<00:12, 153MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  70% 4.36G/6.24G [00:18<00:12, 149MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  70% 4.38G/6.24G [00:18<00:13, 140MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  71% 4.41G/6.24G [00:18<00:10, 171MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  71% 4.44G/6.24G [00:19<00:11, 163MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  72% 4.47G/6.24G [00:19<00:10, 172MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  72% 4.49G/6.24G [00:19<00:12, 141MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  72% 4.52G/6.24G [00:19<00:10, 168MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  73% 4.55G/6.24G [00:19<00:08, 189MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  73% 4.57G/6.24G [00:19<00:09, 183MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  74% 4.60G/6.24G [00:19<00:08, 203MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  74% 4.63G/6.24G [00:20<00:07, 214MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  75% 4.67G/6.24G [00:20<00:06, 238MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  75% 4.70G/6.24G [00:20<00:06, 225MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  76% 4.73G/6.24G [00:20<00:08, 179MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  76% 4.75G/6.24G [00:20<00:11, 134MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  77% 4.78G/6.24G [00:20<00:08, 164MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  77% 4.81G/6.24G [00:21<00:07, 185MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  78% 4.84G/6.24G [00:21<00:07, 197MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  78% 4.88G/6.24G [00:21<00:06, 197MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  79% 4.91G/6.24G [00:21<00:06, 219MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  79% 4.94G/6.24G [00:21<00:05, 230MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  80% 4.97G/6.24G [00:21<00:05, 236MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  80% 5.00G/6.24G [00:22<00:07, 172MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  81% 5.04G/6.24G [00:22<00:07, 151MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  81% 5.06G/6.24G [00:22<00:08, 145MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  82% 5.10G/6.24G [00:22<00:07, 153MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  82% 5.13G/6.24G [00:22<00:06, 171MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  83% 5.16G/6.24G [00:22<00:05, 189MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  83% 5.19G/6.24G [00:23<00:05, 197MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  84% 5.22G/6.24G [00:23<00:05, 191MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  84% 5.25G/6.24G [00:23<00:05, 196MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  85% 5.28G/6.24G [00:23<00:04, 210MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  85% 5.32G/6.24G [00:23<00:04, 215MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  86% 5.35G/6.24G [00:23<00:04, 223MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  86% 5.38G/6.24G [00:24<00:05, 167MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  87% 5.41G/6.24G [00:24<00:04, 182MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  87% 5.45G/6.24G [00:24<00:03, 226MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  88% 5.49G/6.24G [00:24<00:02, 255MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  89% 5.54G/6.24G [00:24<00:02, 275MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  89% 5.57G/6.24G [00:24<00:02, 247MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  90% 5.60G/6.24G [00:24<00:02, 238MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  90% 5.63G/6.24G [00:25<00:03, 165MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  91% 5.65G/6.24G [00:25<00:04, 132MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  91% 5.68G/6.24G [00:25<00:03, 157MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  91% 5.70G/6.24G [00:25<00:03, 159MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  92% 5.74G/6.24G [00:25<00:02, 183MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  92% 5.77G/6.24G [00:26<00:03, 142MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  93% 5.79G/6.24G [00:26<00:03, 119MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  93% 5.81G/6.24G [00:26<00:04, 103MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  94% 5.84G/6.24G [00:26<00:03, 129MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  94% 5.87G/6.24G [00:27<00:02, 156MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  95% 5.90G/6.24G [00:27<00:01, 186MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  95% 5.93G/6.24G [00:27<00:01, 195MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  96% 5.97G/6.24G [00:27<00:01, 153MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  96% 6.00G/6.24G [00:27<00:01, 135MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  97% 6.03G/6.24G [00:28<00:01, 158MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  97% 6.05G/6.24G [00:28<00:01, 148MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  97% 6.07G/6.24G [00:28<00:01, 146MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  98% 6.10G/6.24G [00:28<00:00, 176MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  98% 6.13G/6.24G [00:28<00:00, 198MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  99% 6.17G/6.24G [00:28<00:00, 211MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  99% 6.20G/6.24G [00:28<00:00, 225MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin: 100% 6.24G/6.24G [00:28<00:00, 215MB/s]\n",
            "Downloading shards: 100% 3/3 [01:48<00:00, 36.22s/it]\n",
            "(…)rge-patch14-336/resolve/main/config.json: 100% 4.76k/4.76k [00:00<00:00, 22.4MB/s]\n",
            "Loading checkpoint shards: 100% 3/3 [00:21<00:00,  7.06s/it]\n",
            "(…)-13b/resolve/main/generation_config.json: 100% 154/154 [00:00<00:00, 839kB/s]\n",
            "(…)36/resolve/main/preprocessor_config.json: 100% 316/316 [00:00<00:00, 1.92MB/s]\n",
            "pytorch_model.bin: 100% 1.71G/1.71G [00:09<00:00, 185MB/s]\n",
            "The image features a red fire-breathing toy, resembling a small lizard or a dragon, standing on a wooden dock. The toy is positioned in the center of the scene, with its fire-breathing effect creating a captivating visual. The wooden dock extends across the image, providing a sense of depth and a natural setting for the toy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# two-shots\n",
        "## #1\n",
        "!cd LLaVA; python -m llava.eval.run_llava \\\n",
        "    --model-path liuhaotian/llava-v1.5-13b  \\\n",
        "    --image-file \"https://llava-vl.github.io/static/images/view.jpg\" \\\n",
        "    --query \"USER: Can you describe this image?\\n<image-placeholder>\\nASSISTANT: \""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWb2TlDr8Gpq",
        "outputId": "44ee1b6d-75e1-4b9e-f3c7-e2458549f170"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-10-21 06:40:45,087] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-10-21 06:40:46.881490: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Loading checkpoint shards: 100% 3/3 [00:22<00:00,  7.36s/it]\n",
            "The image features a wooden pier extending out into a large body of water, possibly a lake or a bay. The pier is surrounded by a serene and picturesque environment, with mountains visible in the background. The scene is further enhanced by the presence of a few trees scattered around the area. The overall atmosphere of the image is tranquil and inviting, making it an ideal spot for relaxation and contemplation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# two-shots\n",
        "## #2\n",
        "response1=\"The image features a wooden pier extending out into a large body of water, possibly a lake or a bay. The pier is surrounded by a serene and picturesque environment, with mountains visible in the background. The scene is further enhanced by the presence of a few trees scattered around the area. The overall atmosphere of the image is tranquil and inviting, making it an ideal spot for relaxation and contemplation.\"\n",
        "!cd LLaVA; python -m llava.eval.run_llava \\\n",
        "    --model-path liuhaotian/llava-v1.5-13b  \\\n",
        "    --image-file \"https://llava-vl.github.io/static/images/view.jpg,/content/LLaVA/images/llava_logo.png\" \\\n",
        "    --query f\"USER: Can you describe this image?\\n<image-placeholder>\\nASSISTANT: {response1}\\nUSER: Can you describe this image?\\n<image-placeholder>\\nASSISTANT: \""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7otVXOwb8Cg2",
        "outputId": "6dae0660-6197-41f0-e93b-0258026f73fb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-10-21 06:45:03,473] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-10-21 06:45:05.277912: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Loading checkpoint shards: 100% 3/3 [00:21<00:00,  7.04s/it]\n",
            "The image features a red toy animal, possibly a toy horse, with flames coming out of its back. The toy is placed on a surface, possibly a table, and is wearing glasses. The overall appearance of the toy is unique and eye-catching, with the combination of the red color, flames, and glasses creating a distinctive and interesting visual effect.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNu08MOSvo5DLzO3DiH9uWc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}