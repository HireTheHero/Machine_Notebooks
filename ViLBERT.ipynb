{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ViLBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "1DNh737Q1HEXT0nyGfgxB71zI0slNanwV",
      "authorship_tag": "ABX9TyPCuNIWyXcYY+6F1yJD42to",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WannaGetDSJobInSanFrancisco/Machine_Notebooks/blob/main/ViLBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rLYLqyWM8hI"
      },
      "source": [
        "# ViLBERT fine-tuning / evaluation for Hate Speech dataset\n",
        "- Operation checked at: Colab PRO GPU mode or purchased large storage (>=approx 100GB)\n",
        "  - Similar environment with Linux should be fine, but not tested"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fgEiawZNF7I"
      },
      "source": [
        "## Module Setup\n",
        "- https://github.com/facebookresearch/vilbert-multi-task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBTIBgNvQ2Si"
      },
      "source": [
        "### requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAnQkpGoNBzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23e447e1-d88f-4b09-8ef9-387ecfc5e851"
      },
      "source": [
        "# !conda create -n vilbert-mt python=3.6\n",
        "# !conda activate vilbert-mt\n",
        "!git clone --recursive https://github.com/facebookresearch/vilbert-multi-task.git\n",
        "%cd vilbert-multi-task\n",
        "# https://stackoverflow.com/questions/22250483/stop-pip-from-failing-on-single-package-when-installing-with-requirements-txt\n",
        "!cat requirements.txt | sed -e '/^\\s*#.*$/d' -e '/^\\s*$/d' | xargs -n 1 pip install"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'vilbert-multi-task'...\n",
            "remote: Enumerating objects: 2005, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 2005 (delta 0), reused 0 (delta 0), pack-reused 2002\u001b[K\n",
            "Receiving objects: 100% (2005/2005), 117.16 MiB | 22.03 MiB/s, done.\n",
            "Resolving deltas: 100% (1436/1436), done.\n",
            "Submodule 'tools/refer' (https://github.com/lichengunc/refer.git) registered for path 'tools/refer'\n",
            "Cloning into '/content/vilbert-multi-task/tools/refer'...\n",
            "remote: Enumerating objects: 185, done.        \n",
            "remote: Counting objects: 100% (3/3), done.        \n",
            "remote: Compressing objects: 100% (3/3), done.        \n",
            "remote: Total 185 (delta 0), reused 0 (delta 0), pack-reused 182        \n",
            "Receiving objects: 100% (185/185), 71.66 MiB | 32.70 MiB/s, done.\n",
            "Resolving deltas: 100% (72/72), done.\n",
            "Submodule path 'tools/refer': checked out 'd23ec5d8e84baf858c58af119799e26846aa5261'\n",
            "/content/vilbert-multi-task\n",
            "Collecting pytorch-transformers==1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/b5/2d78e74001af0152ee61d5ad4e290aec9a1e43925b21df2dc74ec100f1ab/pytorch_transformers-1.0.0-py3-none-any.whl (137kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 8.5MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 14.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers==1.0.0) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers==1.0.0) (1.19.5)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers==1.0.0) (1.8.1+cu101)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/f2/52bf45246ad421cdd8c80a5c0f3e8f082e818d0467cde6aa8294258d1b4a/boto3-1.17.55-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 15.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers==1.0.0) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers==1.0.0) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-transformers==1.0.0) (3.7.4.3)\n",
            "Collecting botocore<1.21.0,>=1.20.55\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/b0/d382d472989ce23bee0a36f8bd0c326d4694496611a7fe41fae51d71bf46/botocore-1.20.55-py2.py3-none-any.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 21.1MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/95/91a1b99e4ef46bb915167b04aa26aec74dad5356d13d487a90f7d22994ee/s3transfer-0.4.1-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.8MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers==1.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers==1.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers==1.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers==1.0.0) (2020.12.5)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.55->boto3->pytorch-transformers==1.0.0) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.55->boto3->pytorch-transformers==1.0.0) (1.15.0)\n",
            "\u001b[31mERROR: botocore 1.20.55 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sentencepiece, jmespath, botocore, s3transfer, boto3, pytorch-transformers\n",
            "Successfully installed boto3-1.17.55 botocore-1.20.55 jmespath-0.10.0 pytorch-transformers-1.0.0 s3transfer-0.4.1 sentencepiece-0.1.95\n",
            "Collecting numpy==1.16.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/d1/45be1144b03b6b1e24f9a924f23f66b4ad030d834ad31fb9e5581bd328af/numpy-1.16.4-cp37-cp37m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 134kB/s \n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pyarrow 3.0.0 has requirement numpy>=1.16.6, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: astropy 4.2.1 has requirement numpy>=1.17, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "Successfully installed numpy-1.16.4\n",
            "Collecting lmdb==0.94\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cb/31/5be8f436b56733d9e69c721c358502f4d77b627489a459978686be7db65f/lmdb-0.94.tar.gz (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 7.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: lmdb\n",
            "  Building wheel for lmdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lmdb: filename=lmdb-0.94-cp37-cp37m-linux_x86_64.whl size=219731 sha256=e511e7775b1604ad5e9f4f6b81d13dafe34f3f5d9ee2041485df59f3b83ec598\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/40/51/3fe10a4a559a91352579a27cbcca490f279bacb54209713c4b\n",
            "Successfully built lmdb\n",
            "Installing collected packages: lmdb\n",
            "  Found existing installation: lmdb 0.99\n",
            "    Uninstalling lmdb-0.99:\n",
            "      Successfully uninstalled lmdb-0.99\n",
            "Successfully installed lmdb-0.94\n",
            "Collecting tensorboardX==1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/22/43f4f0318f7c68a1000dbb700a353b745584bc2397437832d15ba69ea5f1/tensorboardX-1.2-py2.py3-none-any.whl (44kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.2) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.2) (1.16.4)\n",
            "Requirement already satisfied: protobuf>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.2) (3.12.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=0.3.2->tensorboardX==1.2) (54.2.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-1.2\n",
            "Collecting tensorflow==2.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/0a/012cc33c643d844433d13001dd1db179e7020b05ddbbd0a9dc86c38a8efa/tensorflow-2.4.0-cp37-cp37m-manylinux2010_x86_64.whl (394.7MB)\n",
            "\u001b[K     |████████████████████████████████| 394.7MB 36kB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.6.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.1.2)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.7.4.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (2.4.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.36.2)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.12)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.12.4)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.12.1)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (2.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.3.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (2.4.1)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.15.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.32.0)\n",
            "Collecting numpy~=1.19.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/d6/a6aaa29fea945bc6c61d11f6e0697b325ff7446de5ffd62c2fa02f627048/numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8MB 52.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow==2.4.0) (54.2.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.28.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (3.3.4)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2.10)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (3.10.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (3.4.1)\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, tensorflow\n",
            "  Found existing installation: numpy 1.16.4\n",
            "    Uninstalling numpy-1.16.4:\n",
            "      Successfully uninstalled numpy-1.16.4\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed numpy-1.19.5 tensorflow-2.4.0\n",
            "Collecting tensorpack==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/69/c825f9fbd60ebca7387ab81f5704bf43ba6605c452555e305cbe6fcca61d/tensorpack-0.9.4-py2.py3-none-any.whl (273kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyzmq>=16 in /usr/local/lib/python3.7/dist-packages (from tensorpack==0.9.4) (22.0.3)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorpack==0.9.4) (1.19.5)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from tensorpack==0.9.4) (0.8.9)\n",
            "Requirement already satisfied: tqdm>4.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorpack==0.9.4) (4.41.1)\n",
            "Collecting msgpack-numpy>=0.4.4.2\n",
            "  Downloading https://files.pythonhosted.org/packages/19/05/05b8d7c69c6abb36a34325cc3150089bdafc359f0a81fb998d93c5d5c737/msgpack_numpy-0.4.7.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from tensorpack==0.9.4) (1.0.2)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from tensorpack==0.9.4) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorpack==0.9.4) (1.15.0)\n",
            "Installing collected packages: msgpack-numpy, tensorpack\n",
            "Successfully installed msgpack-numpy-0.4.7.1 tensorpack-0.9.4\n",
            "Collecting tqdm==4.31.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.5MB/s \n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.31.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.31.1 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed tqdm-4.31.1\n",
            "Requirement already satisfied: easydict==1.9 in /usr/local/lib/python3.7/dist-packages (1.9)\n",
            "Collecting PyYAML==5.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/e8/b3212641ee2718d556df0f23f78de8303f068fe29cdaa7a91018849582fe/PyYAML-5.1.2.tar.gz (265kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 7.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: PyYAML\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.1.2-cp37-cp37m-linux_x86_64.whl size=44103 sha256=83b6b7c1f1eb83ffdd4566091c66e7e75a756d5d59c0feb6c0444efe86012370\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/45/dd/65f0b38450c47cf7e5312883deb97d065e030c5cca0a365030\n",
            "Successfully built PyYAML\n",
            "Installing collected packages: PyYAML\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-5.1.2\n",
            "Collecting jsonlines==1.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/9a/ab96291470e305504aa4b7a2e0ec132e930da89eb3ca7a82fbe03167c131/jsonlines-1.2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from jsonlines==1.2.0) (1.15.0)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-1.2.0\n",
            "Collecting json-lines==0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/7f/0f/79c96c0d26b276c583484fe8209e5ebbb416a920309568650325f6e1de73/json_lines-0.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from json-lines==0.5.0) (1.15.0)\n",
            "Installing collected packages: json-lines\n",
            "Successfully installed json-lines-0.5.0\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (0.29.22)\n",
            "Collecting python-prctl\n",
            "  Downloading https://files.pythonhosted.org/packages/c0/99/be5393cfe9c16376b4f515d90a68b11f1840143ac1890e9008bc176cf6a6/python-prctl-1.8.1.tar.gz\n",
            "\u001b[31mERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: msgpack-numpy in /usr/local/lib/python3.7/dist-packages (0.4.7.1)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from msgpack-numpy) (1.19.5)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from msgpack-numpy) (1.0.2)\n",
            "Collecting opencv-python==4.2.0.34\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/f0/cfe88d262c67825b20d396c778beca21829da061717c7aaa8b421ae5132e/opencv_python-4.2.0.34-cp37-cp37m-manylinux1_x86_64.whl (28.2MB)\n",
            "\u001b[K     |████████████████████████████████| 28.2MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==4.2.0.34) (1.19.5)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: opencv-python\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "Successfully installed opencv-python-4.2.0.34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuQKMp3GhSCa"
      },
      "source": [
        "### install the module failed in requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Uj4965VPdR2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4711fe69-e7dd-45c7-ab47-373ccfd1ccb1"
      },
      "source": [
        "!apt-get -qq install -y python-prctl\n",
        "# apt-get, not pip, worked for this module"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package python-prctl.\n",
            "(Reading database ... 160983 files and directories currently installed.)\n",
            "Preparing to unpack .../python-prctl_1.6.1-2build1_amd64.deb ...\n",
            "Unpacking python-prctl (1.6.1-2build1) ...\n",
            "Setting up python-prctl (1.6.1-2build1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndqkGgTyR6wZ"
      },
      "source": [
        "### apex\n",
        "- https://github.com/NVIDIA/apex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBZhkh8OR3IR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c3f14f69-8768-420d-8cd7-76b495fc4536"
      },
      "source": [
        "# https://stackoverflow.com/questions/57284345/how-to-install-nvidia-apex-on-google-colab\n",
        "!git clone https://github.com/NVIDIA/apex\n",
        "%cd apex\n",
        "# !pip install -v --disable-pip-version-check --no-cache-dir ./\n",
        "# https://github.com/NVIDIA/apex/issues/161\n",
        "!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" .\n",
        "%cd ../\n",
        "%pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 8038, done.\u001b[K\n",
            "remote: Counting objects: 100% (125/125), done.\u001b[K\n",
            "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
            "remote: Total 8038 (delta 58), reused 69 (delta 30), pack-reused 7913\u001b[K\n",
            "Receiving objects: 100% (8038/8038), 14.11 MiB | 19.49 MiB/s, done.\n",
            "Resolving deltas: 100% (5457/5457), done.\n",
            "/content/vilbert-multi-task/apex\n",
            "/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-3bl3vd01\n",
            "Created temporary directory: /tmp/pip-req-tracker-1t31vxio\n",
            "Created requirements tracker '/tmp/pip-req-tracker-1t31vxio'\n",
            "Created temporary directory: /tmp/pip-install-fdeexr5t\n",
            "Processing /content/vilbert-multi-task/apex\n",
            "  Created temporary directory: /tmp/pip-req-build-5a8l98kh\n",
            "  Added file:///content/vilbert-multi-task/apex to build tracker '/tmp/pip-req-tracker-1t31vxio'\n",
            "    Running setup.py (path:/tmp/pip-req-build-5a8l98kh/setup.py) egg_info for package from file:///content/vilbert-multi-task/apex\n",
            "    Running command python setup.py egg_info\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.8.1+cu101\n",
            "\n",
            "\n",
            "    running egg_info\n",
            "    creating /tmp/pip-req-build-5a8l98kh/pip-egg-info/apex.egg-info\n",
            "    writing /tmp/pip-req-build-5a8l98kh/pip-egg-info/apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-req-build-5a8l98kh/pip-egg-info/apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-req-build-5a8l98kh/pip-egg-info/apex.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-req-build-5a8l98kh/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    writing manifest file '/tmp/pip-req-build-5a8l98kh/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    /tmp/pip-req-build-5a8l98kh/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  Source in /tmp/pip-req-build-5a8l98kh has version 0.1, which satisfies requirement apex==0.1 from file:///content/vilbert-multi-task/apex\n",
            "  Removed apex==0.1 from file:///content/vilbert-multi-task/apex from build tracker '/tmp/pip-req-tracker-1t31vxio'\n",
            "Skipping wheel build for apex, due to binaries being disabled for it.\n",
            "Installing collected packages: apex\n",
            "  Created temporary directory: /tmp/pip-record-fq7ffdzc\n",
            "    Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-5a8l98kh/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-5a8l98kh/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-fq7ffdzc/install-record.txt --single-version-externally-managed --compile\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.8.1+cu101\n",
            "\n",
            "\n",
            "    /tmp/pip-req-build-5a8l98kh/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "\n",
            "    Compiling cuda extensions with\n",
            "    nvcc: NVIDIA (R) Cuda compiler driver\n",
            "    Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "    Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "    Cuda compilation tools, release 11.0, V11.0.221\n",
            "    Build cuda_11.0_bu.TC445_37.28845127_0\n",
            "    from /usr/local/cuda/bin\n",
            "\n",
            "    Traceback (most recent call last):\n",
            "      File \"<string>\", line 1, in <module>\n",
            "      File \"/tmp/pip-req-build-5a8l98kh/setup.py\", line 171, in <module>\n",
            "        check_cuda_torch_binary_vs_bare_metal(torch.utils.cpp_extension.CUDA_HOME)\n",
            "      File \"/tmp/pip-req-build-5a8l98kh/setup.py\", line 106, in check_cuda_torch_binary_vs_bare_metal\n",
            "        \"https://github.com/NVIDIA/apex/pull/323#discussion_r287021798.  \"\n",
            "    RuntimeError: Cuda extensions are being compiled with a version of Cuda that does not match the version used to compile Pytorch binaries.  Pytorch binaries were compiled with Cuda 10.1.\n",
            "    In some cases, a minor-version mismatch will not cause later errors:  https://github.com/NVIDIA/apex/pull/323#discussion_r287021798.  You can try commenting out this check (at your own risk).\n",
            "    Running setup.py install for apex ... \u001b[?25l\u001b[?25herror\n",
            "Cleaning up...\n",
            "  Removing source in /tmp/pip-req-build-5a8l98kh\n",
            "Removed build tracker '/tmp/pip-req-tracker-1t31vxio'\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-5a8l98kh/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-5a8l98kh/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-fq7ffdzc/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\u001b[0m\n",
            "Exception information:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 153, in _main\n",
            "    status = self.run(options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 455, in run\n",
            "    use_user_site=options.use_user_site,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/req/__init__.py\", line 62, in install_given_reqs\n",
            "    **kwargs\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/req/req_install.py\", line 888, in install\n",
            "    cwd=self.unpacked_source_directory,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/subprocess.py\", line 275, in runner\n",
            "    spinner=spinner,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/subprocess.py\", line 242, in call_subprocess\n",
            "    raise InstallationError(exc_msg)\n",
            "pip._internal.exceptions.InstallationError: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-5a8l98kh/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-5a8l98kh/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-fq7ffdzc/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\n",
            "/content/vilbert-multi-task\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/vilbert-multi-task'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lNfrmdmTsn1"
      },
      "source": [
        "### setup.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4je-VOhTaEh",
        "outputId": "f7dacd1f-49cf-40d6-8453-4f895806dfd7"
      },
      "source": [
        "!python setup.py develop"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running develop\n",
            "running egg_info\n",
            "creating vilbert_multi_task.egg-info\n",
            "writing vilbert_multi_task.egg-info/PKG-INFO\n",
            "writing dependency_links to vilbert_multi_task.egg-info/dependency_links.txt\n",
            "writing top-level names to vilbert_multi_task.egg-info/top_level.txt\n",
            "writing manifest file 'vilbert_multi_task.egg-info/SOURCES.txt'\n",
            "writing manifest file 'vilbert_multi_task.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.7/dist-packages/vilbert-multi-task.egg-link (link to .)\n",
            "Adding vilbert-multi-task 0.1.0 to easy-install.pth file\n",
            "\n",
            "Installed /content/vilbert-multi-task\n",
            "Processing dependencies for vilbert-multi-task==0.1.0\n",
            "Finished processing dependencies for vilbert-multi-task==0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HI14_EDWPJG"
      },
      "source": [
        "### error handling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCb1H1suWU1p",
        "outputId": "72224a02-df10-4e65-a126-8f84f7125cbb"
      },
      "source": [
        "# TypeError: Couldn't build proto file into descriptor pool!\n",
        "## https://github.com/ValvePython/csgo/issues/8\n",
        "!pip uninstall -y protobuf\n",
        "!pip install --no-binary=protobuf protobuf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling protobuf-3.12.4:\n",
            "  Successfully uninstalled protobuf-3.12.4\n",
            "Collecting protobuf\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/c8/e90238d5c0de6808da7b2529f4b2bd66c59ee73caabdd9d5bc351512f8b6/protobuf-3.15.8.tar.gz (228kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf) (1.15.0)\n",
            "Skipping wheel build for protobuf, due to binaries being disabled for it.\n",
            "Installing collected packages: protobuf\n",
            "    Running setup.py install for protobuf ... \u001b[?25l\u001b[?25hdone\n",
            "Successfully installed protobuf-3.15.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uko4GMXDXAGv",
        "outputId": "bae40590-793b-4526-d717-3b4091c35c05"
      },
      "source": [
        "# TypeError: Conflict register for file \"tensorboard/compat/proto/tensor_shape.proto\": tensorboard.TensorShapeProto is already defined in file \"tensorboardX/src/tensor_shape.proto\".\n",
        "## xx\n",
        "# !pip install allennlp\n",
        "# !pip install allennlp-models\n",
        "!pip install tensorboardX==1.8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX==1.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/12/dcaf67e1312475b26db9e45e7bb6f32b540671a9ee120b3a72d9e09bc517/tensorboardX-1.8-py2.py3-none-any.whl (216kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 19.8MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 16.7MB/s eta 0:00:01\r\u001b[K     |████▌                           | 30kB 14.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 40kB 13.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 51kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 61kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 71kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 81kB 10.6MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 92kB 10.0MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 102kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 112kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 122kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 133kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 143kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 153kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 163kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 174kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 184kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 194kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 204kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 215kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 225kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.8) (3.15.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.8) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.8) (1.19.5)\n",
            "Installing collected packages: tensorboardX\n",
            "  Found existing installation: tensorboardX 1.2\n",
            "    Uninstalling tensorboardX-1.2:\n",
            "      Successfully uninstalled tensorboardX-1.2\n",
            "Successfully installed tensorboardX-1.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oEGQeZZer9H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f3520b46-49e6-42b8-a7d8-4c92ed391e7c"
      },
      "source": [
        "#   File \"/content/vilbert-multi-task/tools/refer/refer.py\", line 49\n",
        "#    print 'loading dataset %s into memory...' % dataset                                          ^\n",
        "# SyntaxError: Missing parentheses in call to 'print'. Did you mean print('loading dataset %s into memory...' % dataset)?\n",
        "## So they're using python2 script :(\n",
        "### https://github.com/facebookresearch/vilbert-multi-task/issues/33\n",
        "%rm -r tools/refer\n",
        "%mkdir tools/refer\n",
        "!git clone -b python3 https://github.com/lichengunc/refer tools/refer\n",
        "%cd tools/refer\n",
        "!python setup.py install\n",
        "!make\n",
        "%cd ../\n",
        "%cd ../\n",
        "%pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tools/refer'...\n",
            "remote: Enumerating objects: 185, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 185 (delta 0), reused 0 (delta 0), pack-reused 182\u001b[K\n",
            "Receiving objects: 100% (185/185), 71.66 MiB | 32.88 MiB/s, done.\n",
            "Resolving deltas: 100% (72/72), done.\n",
            "/content/vilbert-multi-task/tools/refer\n",
            "Compiling external/_mask.pyx because it changed.\n",
            "[1/1] Cythonizing external/_mask.pyx\n",
            "/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/vilbert-multi-task/tools/refer/external/_mask.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "running install\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/external\n",
            "copying external/mask.py -> build/lib.linux-x86_64-3.7/external\n",
            "copying external/__init__.py -> build/lib.linux-x86_64-3.7/external\n",
            "running build_ext\n",
            "building 'external._mask' extension\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/external\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -Iexternal -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I/usr/include/python3.7m -c external/_mask.c -o build/temp.linux-x86_64-3.7/external/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -Iexternal -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I/usr/include/python3.7m -c external/maskApi.c -o build/temp.linux-x86_64-3.7/external/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
            "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
            "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:165:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:165:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:211:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
            "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:211:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
            "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:219:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
            "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:219:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
            "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
            "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:227:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
            "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:227:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
            "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/external/_mask.o build/temp.linux-x86_64-3.7/external/maskApi.o -o build/lib.linux-x86_64-3.7/external/_mask.cpython-37m-x86_64-linux-gnu.so\n",
            "running install_lib\n",
            "creating /usr/local/lib/python3.7/dist-packages/external\n",
            "copying build/lib.linux-x86_64-3.7/external/mask.py -> /usr/local/lib/python3.7/dist-packages/external\n",
            "copying build/lib.linux-x86_64-3.7/external/_mask.cpython-37m-x86_64-linux-gnu.so -> /usr/local/lib/python3.7/dist-packages/external\n",
            "copying build/lib.linux-x86_64-3.7/external/__init__.py -> /usr/local/lib/python3.7/dist-packages/external\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/external/mask.py to mask.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/external/__init__.py to __init__.cpython-37.pyc\n",
            "running install_egg_info\n",
            "Writing /usr/local/lib/python3.7/dist-packages/external-2.0.egg-info\n",
            "# install pycocotools/mask locally\n",
            "# copy from https://github.com/pdollar/coco.git\n",
            "python setup.py build_ext --inplace\n",
            "running build_ext\n",
            "building 'external._mask' extension\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -Iexternal -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I/usr/include/python3.7m -c external/_mask.c -o build/temp.linux-x86_64-3.7/external/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -Iexternal -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I/usr/include/python3.7m -c external/maskApi.c -o build/temp.linux-x86_64-3.7/external/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
            "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
            "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:165:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:165:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:211:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
            "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:211:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
            "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:219:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
            "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:219:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
            "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
            "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:227:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
            "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexternal/maskApi.c:227:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
            "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/external/_mask.o build/temp.linux-x86_64-3.7/external/maskApi.o -o /content/vilbert-multi-task/tools/refer/external/_mask.cpython-37m-x86_64-linux-gnu.so\n",
            "rm -rf build\n",
            "/content/vilbert-multi-task/tools\n",
            "/content/vilbert-multi-task\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/vilbert-multi-task'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_e6n1GnU5cS"
      },
      "source": [
        "## download model\n",
        "- https://stackoverflow.com/questions/49576657/is-there-anyway-i-can-download-the-file-in-google-colaboratory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--zTfu61U4n1",
        "outputId": "d80792c0-1650-422c-ff0e-dcfb1d01ae20"
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/vilbert-multi-task/multi_task_model.bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-22 00:36:26--  https://dl.fbaipublicfiles.com/vilbert-multi-task/multi_task_model.bin\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 172.67.9.4, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1072254755 (1023M) [application/octet-stream]\n",
            "Saving to: ‘multi_task_model.bin’\n",
            "\n",
            "multi_task_model.bi 100%[===================>]   1023M  59.7MB/s    in 16s     \n",
            "\n",
            "2021-04-22 00:36:42 (62.8 MB/s) - ‘multi_task_model.bin’ saved [1072254755/1072254755]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYEkc3kmmW2S"
      },
      "source": [
        "## load data\n",
        "- https://github.com/facebookresearch/vilbert-multi-task/tree/master/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwItao4-maiP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c93ca910-218a-45a3-af5c-e1206f6ab5c6"
      },
      "source": [
        "# %cd data\n",
        "!wget https://dl.fbaipublicfiles.com/vilbert-multi-task/datasets.tar.gz\n",
        "# !tar tvf datasets.tar.gz\n",
        "!tar xvf datasets.tar.gz $(tar tf datasets.tar.gz | grep 'VQA')\n",
        "# !tar xvf datasets.tar.gz $(tar tf datasets.tar.gz | grep -i 'coco')\n",
        "# !tar xf datasets.tar.gz --wildcards *coco\n",
        "# !tar xf datasets.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-22 00:36:43--  https://dl.fbaipublicfiles.com/vilbert-multi-task/datasets.tar.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 172.67.9.4, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 97480948100 (91G) [application/gzip]\n",
            "Saving to: ‘datasets.tar.gz’\n",
            "\n",
            "datasets.tar.gz     100%[===================>]  90.79G  67.9MB/s    in 27m 48s \n",
            "\n",
            "2021-04-22 01:04:31 (55.7 MB/s) - ‘datasets.tar.gz’ saved [97480948100/97480948100]\n",
            "\n",
            "datasets/VQA/\n",
            "datasets/VQA/cache/\n",
            "datasets/VQA/cache/train_target.pkl\n",
            "datasets/VQA/cache/trainval_ans2label.pkl\n",
            "datasets/VQA/cache/trainval_label2ans.pkl\n",
            "datasets/VQA/cache/val_target.pkl\n",
            "datasets/VQA/cache/coco_test_ids.npy\n",
            "datasets/VQA/cache/VQA_trainval_23.pkl\n",
            "datasets/VQA/cache/VQA_minval_23.pkl\n",
            "datasets/VQA/cache/coco_test_ids_small.npy\n",
            "datasets/VQA/cache/VQA_trainval_16.pkl\n",
            "datasets/VQA/cache/VQA_minval_16.pkl\n",
            "datasets/VQA/cache/VQA_test_23_cleaned.pkl\n",
            "datasets/VQA/cache/VQA_trainval_23_cleaned.pkl\n",
            "datasets/VQA/cache/VQA_minval_23_cleaned.pkl\n",
            "datasets/VQA/cache/VQA_trainval_23_cleaned_final.pkl\n",
            "datasets/VQA/cache/VQA_trainval_23_cleanedfinal.pkl\n",
            "datasets/VQA/v2_mscoco_train2014_annotations.json\n",
            "datasets/VQA/v2_mscoco_val2014_annotations.json\n",
            "datasets/VQA/v2_OpenEnded_mscoco_test2015_questions.json\n",
            "datasets/VQA/v2_OpenEnded_mscoco_test-dev2015_questions.json\n",
            "datasets/VQA/v2_OpenEnded_mscoco_train2014_questions.json\n",
            "datasets/VQA/v2_OpenEnded_mscoco_val2014_questions.json\n",
            "tar: datasets/VQA/cache: Not found in archive\n",
            "tar: datasets/VQA/cache/train_target.pkl: Not found in archive\n",
            "tar: datasets/VQA/cache/trainval_ans2label.pkl: Not found in archive\n",
            "tar: datasets/VQA/cache/trainval_label2ans.pkl: Not found in archive\n",
            "tar: datasets/VQA/cache/val_target.pkl: Not found in archive\n",
            "tar: datasets/VQA/cache/coco_test_ids.npy: Not found in archive\n",
            "tar: datasets/VQA/cache/VQA_trainval_23.pkl: Not found in archive\n",
            "tar: datasets/VQA/cache/VQA_minval_23.pkl: Not found in archive\n",
            "tar: datasets/VQA/cache/coco_test_ids_small.npy: Not found in archive\n",
            "tar: datasets/VQA/cache/VQA_trainval_16.pkl: Not found in archive\n",
            "tar: datasets/VQA/cache/VQA_minval_16.pkl: Not found in archive\n",
            "tar: datasets/VQA/cache/VQA_test_23_cleaned.pkl: Not found in archive\n",
            "tar: datasets/VQA/cache/VQA_trainval_23_cleaned.pkl: Not found in archive\n",
            "tar: datasets/VQA/cache/VQA_minval_23_cleaned.pkl: Not found in archive\n",
            "tar: datasets/VQA/cache/VQA_trainval_23_cleaned_final.pkl: Not found in archive\n",
            "tar: datasets/VQA/cache/VQA_trainval_23_cleanedfinal.pkl: Not found in archive\n",
            "tar: datasets/VQA/v2_mscoco_train2014_annotations.json: Not found in archive\n",
            "tar: datasets/VQA/v2_mscoco_val2014_annotations.json: Not found in archive\n",
            "tar: datasets/VQA/v2_OpenEnded_mscoco_test2015_questions.json: Not found in archive\n",
            "tar: datasets/VQA/v2_OpenEnded_mscoco_test-dev2015_questions.json: Not found in archive\n",
            "tar: datasets/VQA/v2_OpenEnded_mscoco_train2014_questions.json: Not found in archive\n",
            "tar: datasets/VQA/v2_OpenEnded_mscoco_val2014_questions.json: Not found in archive\n",
            "tar: Exiting with failure status due to previous errors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTeHEqhHn9ZO",
        "outputId": "dd77929c-f5df-42da-c996-b379dfc26624"
      },
      "source": [
        "# %cd data/\n",
        "%rm datasets.tar.gz\n",
        "%cd /content/vilbert-multi-task/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'datasets.tar.gz': No such file or directory\n",
            "/content/vilbert-multi-task\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1VkgsohmmHV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abc68d63-1506-40be-90fc-33a526904fac"
      },
      "source": [
        "# !mkdir datasets\n",
        "%cd datasets\n",
        "!mkdir coco\n",
        "%cd coco\n",
        "!mkdir features_100\n",
        "%cd features_100\n",
        "# !mkdir COCO_test_resnext152_faster_rcnn_genome.lmdb\n",
        "!mkdir COCO_trainval_resnext152_faster_rcnn_genome.lmdb\n",
        "!wget https://dl.fbaipublicfiles.com/vilbert-multi-task/datasets/coco/features_100/COCO_trainval_resnext152_faster_rcnn_genome.lmdb/data.mdb && mv data.mdb COCO_trainval_resnext152_faster_rcnn_genome.lmdb/\n",
        "# !wget https://dl.fbaipublicfiles.com/vilbert-multi-task/datasets/coco/features_100/COCO_test_resnext152_faster_rcnn_genome.lmdb/data.mdb && mv data.mdb COCO_test_resnext152_faster_rcnn_genome.lmdb/\n",
        "%cd /content/vilbert-multi-task/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/vilbert-multi-task/datasets\n",
            "/content/vilbert-multi-task/datasets/coco\n",
            "/content/vilbert-multi-task/datasets/coco/features_100\n",
            "--2021-04-22 02:21:57--  https://dl.fbaipublicfiles.com/vilbert-multi-task/datasets/coco/features_100/COCO_trainval_resnext152_faster_rcnn_genome.lmdb/data.mdb\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 101507162112 (95G) [application/octet-stream]\n",
            "Saving to: ‘data.mdb’\n",
            "\n",
            "data.mdb            100%[===================>]  94.54G  41.0MB/s    in 41m 3s  \n",
            "\n",
            "2021-04-22 03:03:01 (39.3 MB/s) - ‘data.mdb’ saved [101507162112/101507162112]\n",
            "\n",
            "/content/vilbert-multi-task\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbL3ENxrsVW7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d35dacf2-49ee-4a79-bf41-9674694d2b1f"
      },
      "source": [
        "# !mkdir datasets\n",
        "# !mkdir datasets/coco\n",
        "# !mkdir datasets/coco/features_100\n",
        "# !mkdir datasets/coco/features_100/COCO_trainval_resnext152_faster_rcnn_genome.lmdb\n",
        "# %mv features_100/COCO_trainval_resnext152_faster_rcnn_genome.lmdb/data.mdb datasets/coco/features_100/COCO_trainval_resnext152_faster_rcnn_genome.lmdb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat 'features_100/COCO_trainval_resnext152_faster_rcnn_genome.lmdb/data.mdb': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZaa0Gtl1jlC",
        "outputId": "f81902fc-56b9-4d69-9e92-19ac119caa91"
      },
      "source": [
        "%cd /content/vilbert-multi-task/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/vilbert-multi-task\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYUdvXo5cJd0"
      },
      "source": [
        "## Run train_tasks.py as fine tuning\n",
        "- VQA as classification problem\n",
        "  - https://github.com/facebookresearch/vilbert-multi-task/blob/master/vilbert_tasks.yml\n",
        "  - https://arxiv.org/abs/1707.07998"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXlUoEu7cIHH",
        "outputId": "aa4375b3-d91a-4f41-d1ac-a796d4d65374"
      },
      "source": [
        "!python train_tasks.py --bert_model bert-base-uncased --from_pretrained multi_task_model.bin --config_file config/bert_base_6layer_6conect.json --tasks 1 --lr_scheduler 'warmup_linear' --train_iter_gap 4 --task_specific_tokens --save_name finetune_from_multi_task_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-22 03:03:08.924205: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "04/22/2021 03:03:13 - INFO - vilbert.vilbert -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
            "04/22/2021 03:03:13 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "04/22/2021 03:03:14 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to /tmp/tmpynghkq4_\n",
            "100% 231508/231508 [00:00<00:00, 963092.53B/s]\n",
            "04/22/2021 03:03:14 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpynghkq4_ to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "04/22/2021 03:03:14 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "04/22/2021 03:03:14 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpynghkq4_\n",
            "04/22/2021 03:03:14 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "04/22/2021 03:03:14 - INFO - vilbert.task_utils -   Loading VQA Dataset with batch size 128\n",
            "04/22/2021 03:03:14 - INFO - vilbert.datasets.vqa_dataset -   Loading from datasets/VQA/cache/VQA_trainval_23_cleaned.pkl\n",
            "04/22/2021 03:05:08 - INFO - vilbert.datasets.vqa_dataset -   Loading from datasets/VQA/cache/VQA_minval_23_cleaned.pkl\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "04/22/2021 03:05:09 - INFO - vilbert.utils -   logging file at: save/VQA_bert_base_6layer_6conect-finetune_from_multi_task_model/logs\n",
            "04/22/2021 03:05:09 - INFO - vilbert.utils -   loading weights file multi_task_model.bin\n",
            "559 559\n",
            "***** Running training *****\n",
            "  Num Iters:  {'TASK1': 4236}\n",
            "  Batch size:  {'TASK1': 128}\n",
            "  Num steps: 84720\n",
            "Epoch:   0% 0/20 [00:00<?, ?it/s]Traceback (most recent call last):\n",
            "  File \"train_tasks.py\", line 673, in <module>\n",
            "    main()\n",
            "  File \"train_tasks.py\", line 533, in main\n",
            "    task_losses,\n",
            "  File \"/content/vilbert-multi-task/vilbert/task_utils.py\", line 321, in ForwardModelsTrain\n",
            "    task_tokens,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/vilbert-multi-task/vilbert/vilbert.py\", line 1662, in forward\n",
            "    output_all_attention_masks=output_all_attention_masks,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/vilbert-multi-task/vilbert/vilbert.py\", line 1387, in forward\n",
            "    output_all_attention_masks=output_all_attention_masks,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/vilbert-multi-task/vilbert/vilbert.py\", line 1002, in forward\n",
            "    txt_attention_mask2,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/vilbert-multi-task/vilbert/vilbert.py\", line 693, in forward\n",
            "    layer_output = self.output(intermediate_output, attention_output)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/vilbert-multi-task/vilbert/vilbert.py\", line 677, in forward\n",
            "    hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/vilbert-multi-task/vilbert/vilbert.py\", line 315, in forward\n",
            "    s = (x - u).pow(2).mean(-1, keepdim=True)\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 52.00 MiB (GPU 0; 15.90 GiB total capacity; 14.53 GiB already allocated; 17.75 MiB free; 15.00 GiB reserved in total by PyTorch)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkedZVN9T3vt"
      },
      "source": [
        "## fine tune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqF8iRvmyy9l"
      },
      "source": [
        "### init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM-27eYPnJHC"
      },
      "source": [
        "from types import SimpleNamespace\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from torchsummary import summary\n",
        "from pytorch_transformers.tokenization_bert import BertTokenizer\n",
        "\n",
        "from vilbert.vilbert import VILBertForVLTasks, BertConfig, BertForMultiModalPreTraining, BertImageEmbeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY-zKsgbzLWb"
      },
      "source": [
        "### modify path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBf6pFY-Tqcw"
      },
      "source": [
        "# PRETRAINED_MODEL_PATH = \"multi_task_model.bin\"\n",
        "# !python train_tasks.py --bert_model bert-base-uncased --from_pretrained PRETRAINED_MODEL_PATH --config_file config/bert_base_6layer_6conect.json --tasks 1 --lr_scheduler 'warmup_linear' --train_iter_gap 4 --task_specific_tokens --save_name finetune_from_multi_task_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLRTf7cGm3C5"
      },
      "source": [
        "!mkdir save\n",
        "!mkdir save/multitask_model\n",
        "%mv multi_task_model.bin save/multitask_model/pytorch_model_9.bin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlYtLE_DzQGK"
      },
      "source": [
        "### load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0MSP4RPzSYv"
      },
      "source": [
        "args = SimpleNamespace(from_pretrained= \"save/multitask_model/pytorch_model_9.bin\",\n",
        "                       bert_model=\"bert-base-uncased\",\n",
        "                       config_file=\"config/bert_base_6layer_6conect.json\",\n",
        "                       baseline=False,\n",
        "                       num_labels = 3129, \n",
        "                       do_lower_case=True\n",
        "                      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU_QX54cmPKs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a81431d4-dbc8-4284-e86a-11ee1807a1fb"
      },
      "source": [
        "config = BertConfig.from_json_file(args.config_file)\n",
        "if args.baseline:\n",
        "    model = BaseBertForVLTasks.from_pretrained(\n",
        "        args.from_pretrained, config=config, num_labels=args.num_labels, default_gpu=True\n",
        "        )\n",
        "else:\n",
        "    model = VILBertForVLTasks.from_pretrained(\n",
        "        args.from_pretrained, config=config, num_labels=args.num_labels, default_gpu=True\n",
        "        )\n",
        "cuda = torch.cuda.is_available()\n",
        "if cuda: model = model.cuda(0)\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    args.bert_model, do_lower_case=args.do_lower_case\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 688911.76B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Dj4yr3p5fPm"
      },
      "source": [
        "class FeatureExtractor:\n",
        "    MAX_SIZE = 1333\n",
        "    MIN_SIZE = 800\n",
        "    # MIN_SIZE = 10\n",
        "\n",
        "    def __init__(self):\n",
        "        self.args = self.get_parser()\n",
        "        self.detection_model = self._build_detection_model()\n",
        "\n",
        "    def get_parser(self):        \n",
        "        parser = SimpleNamespace(model_file= 'save/resnext_models/model_final.pth',\n",
        "                                #config_file='save/resnext_models/e2e_faster_rcnn_X-152-32x8d-FPN_1x_MLP_2048_FPN_512_train.yaml',\n",
        "                                #config_file=os.path.join(\"save/resnext_models/\", MODEL_NAME), \n",
        "                                config_file=os.path.join(\"save/resnext_models/model.yaml\"), \n",
        "                                batch_size=1,\n",
        "                                num_features=100,\n",
        "                                feature_name=\"fc6\",\n",
        "                                confidence_threshold=0,\n",
        "                                background=False,\n",
        "                                partition=0)\n",
        "        return parser\n",
        "    \n",
        "    def _build_detection_model(self):\n",
        "        cfg.merge_from_file(self.args.config_file)\n",
        "        cfg.freeze()\n",
        "\n",
        "        model = build_detection_model(cfg)\n",
        "        checkpoint = torch.load(self.args.model_file, map_location=torch.device(\"cpu\"))\n",
        "\n",
        "        load_state_dict(model, checkpoint.pop(\"model\"))\n",
        "\n",
        "        model.to(\"cuda\")\n",
        "        model.eval()\n",
        "        return model\n",
        "\n",
        "    def _image_transform(self, path):\n",
        "        img = Image.open(path)\n",
        "        im = np.array(img).astype(np.float32)\n",
        "        # IndexError: too many indices for array, grayscale images\n",
        "        if len(im.shape) < 3:\n",
        "            im = np.repeat(im[:, :, np.newaxis], 3, axis=2)\n",
        "        im = im[:, :, ::-1]\n",
        "        im -= np.array([102.9801, 115.9465, 122.7717])\n",
        "        im_shape = im.shape\n",
        "        im_height = im_shape[0]\n",
        "        im_width = im_shape[1]\n",
        "        im_size_min = np.min(im_shape[0:2])\n",
        "        im_size_max = np.max(im_shape[0:2])\n",
        "\n",
        "        # Scale based on minimum size\n",
        "        im_scale = self.MIN_SIZE / im_size_min\n",
        "\n",
        "        # Prevent the biggest axis from being more than max_size\n",
        "        # If bigger, scale it down\n",
        "        if np.round(im_scale * im_size_max) > self.MAX_SIZE:\n",
        "            im_scale = self.MAX_SIZE / im_size_max\n",
        "\n",
        "        im = cv2.resize(\n",
        "            im, None, None, fx=im_scale, fy=im_scale, interpolation=cv2.INTER_LINEAR\n",
        "        )\n",
        "        img = torch.from_numpy(im).permute(2, 0, 1)\n",
        "\n",
        "        im_info = {\"width\": im_width, \"height\": im_height}\n",
        "\n",
        "        return img, im_scale, im_info\n",
        "\n",
        "    def _process_feature_extraction(\n",
        "        self, output, im_scales, im_infos, feature_name=\"fc6\", conf_thresh=0\n",
        "    ):\n",
        "        batch_size = len(output[0][\"proposals\"])\n",
        "        n_boxes_per_image = [len(boxes) for boxes in output[0][\"proposals\"]]\n",
        "        score_list = output[0][\"scores\"].split(n_boxes_per_image)\n",
        "        score_list = [torch.nn.functional.softmax(x, -1) for x in score_list]\n",
        "        feats = output[0][feature_name].split(n_boxes_per_image)\n",
        "        cur_device = score_list[0].device\n",
        "\n",
        "        feat_list = []\n",
        "        info_list = []\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            dets = output[0][\"proposals\"][i].bbox / im_scales[i]\n",
        "            scores = score_list[i]\n",
        "            max_conf = torch.zeros((scores.shape[0])).to(cur_device)\n",
        "            conf_thresh_tensor = torch.full_like(max_conf, conf_thresh)\n",
        "            start_index = 1\n",
        "            # Column 0 of the scores matrix is for the background class\n",
        "            if self.args.background:\n",
        "                start_index = 0\n",
        "            for cls_ind in range(start_index, scores.shape[1]):\n",
        "                cls_scores = scores[:, cls_ind]\n",
        "                keep = nms(dets, cls_scores, 0.5)\n",
        "                max_conf[keep] = torch.where(\n",
        "                    # Better than max one till now and minimally greater than conf_thresh\n",
        "                    (cls_scores[keep] > max_conf[keep])\n",
        "                    & (cls_scores[keep] > conf_thresh_tensor[keep]),\n",
        "                    cls_scores[keep],\n",
        "                    max_conf[keep],\n",
        "                )\n",
        "\n",
        "            sorted_scores, sorted_indices = torch.sort(max_conf, descending=True)\n",
        "            num_boxes = (sorted_scores[: self.args.num_features] != 0).sum()\n",
        "            keep_boxes = sorted_indices[: self.args.num_features]\n",
        "            feat_list.append(feats[i][keep_boxes])\n",
        "            bbox = output[0][\"proposals\"][i][keep_boxes].bbox / im_scales[i]\n",
        "            # Predict the class label using the scores\n",
        "            objects = torch.argmax(scores[keep_boxes][start_index:], dim=1)\n",
        "            cls_prob = torch.max(scores[keep_boxes][start_index:], dim=1)\n",
        "\n",
        "            info_list.append(\n",
        "                {\n",
        "                    \"bbox\": bbox.cpu().numpy(),\n",
        "                    \"num_boxes\": num_boxes.item(),\n",
        "                    \"objects\": objects.cpu().numpy(),\n",
        "                    \"image_width\": im_infos[i][\"width\"],\n",
        "                    \"image_height\": im_infos[i][\"height\"],\n",
        "                    \"cls_prob\": scores[keep_boxes].cpu().numpy(),\n",
        "                }\n",
        "            )\n",
        "\n",
        "        return feat_list, info_list\n",
        "\n",
        "    def get_detectron_features(self, image_paths):\n",
        "        img_tensor, im_scales, im_infos = [], [], []\n",
        "\n",
        "        for image_path in image_paths:\n",
        "            im, im_scale, im_info = self._image_transform(image_path)\n",
        "            img_tensor.append(im)\n",
        "            im_scales.append(im_scale)\n",
        "            im_infos.append(im_info)\n",
        "\n",
        "        # Image dimensions should be divisible by 32, to allow convolutions\n",
        "        # in detector to work\n",
        "        current_img_list = to_image_list(img_tensor, size_divisible=32)\n",
        "        current_img_list = current_img_list.to(\"cuda\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = self.detection_model(current_img_list)\n",
        "\n",
        "        feat_list = self._process_feature_extraction(\n",
        "            output,\n",
        "            im_scales,\n",
        "            im_infos,\n",
        "            self.args.feature_name,\n",
        "            self.args.confidence_threshold,\n",
        "        )\n",
        "\n",
        "        return feat_list\n",
        "\n",
        "    def _chunks(self, array, chunk_size):\n",
        "        for i in range(0, len(array), chunk_size):\n",
        "            yield array[i : i + chunk_size]\n",
        "\n",
        "    def _save_feature(self, file_name, feature, info):\n",
        "        file_base_name = os.path.basename(file_name)\n",
        "        file_base_name = file_base_name.split(\".\")[0]\n",
        "        info[\"image_id\"] = file_base_name\n",
        "        info[\"features\"] = feature.cpu().numpy()\n",
        "        file_base_name = file_base_name + \".npy\"\n",
        "\n",
        "        np.save(os.path.join(self.args.output_folder, file_base_name), info)\n",
        "\n",
        "    def extract_features(self, image_path):\n",
        "\n",
        "        features, infos = self.get_detectron_features([image_path])\n",
        "\n",
        "        return features, infos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0qKQWfb3ilf"
      },
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "if cuda: model = model.cuda(0)\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    args.bert_model, do_lower_case=args.do_lower_case\n",
        ")\n",
        "\n",
        "# 1: VQA, 2: GenomeQA, 4: Visual7w, 7: Retrieval COCO, 8: Retrieval Flickr30k \n",
        "# 9: refcoco, 10: refcoco+ 11: refcocog, 12: NLVR2, 13: VisualEntailment, 15: GQA, 16: GuessWhat, \n",
        "\n",
        "\n",
        "image_path = 'demo/1.jpg'\n",
        "features, infos = feature_extractor.extract_features(image_path)\n",
        "\n",
        "img = PIL.Image.open(image_path).convert('RGB')\n",
        "img = torch.tensor(np.array(img))\n",
        "\n",
        "plt.axis('off')\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "    \n",
        "query = \"swimming elephant\"\n",
        "task = [9]\n",
        "custom_prediction(query, task, features, infos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_3MyD9h2dZ9"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CsDXehL2_pz"
      },
      "source": [
        "  (bert): BertModel(\n",
        "    (embeddings): BertEmbeddings(\n",
        "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
        "      (position_embeddings): Embedding(512, 768)\n",
        "      (token_type_embeddings): Embedding(2, 768)\n",
        "      (LayerNorm): BertLayerNorm()\n",
        "      (dropout): Dropout(p=0.1, inplace=False)\n",
        "    )\n",
        "    (v_embeddings): BertImageEmbeddings(\n",
        "      (image_embeddings): Linear(in_features=2048, out_features=1024, bias=True)\n",
        "      (image_location_embeddings): Linear(in_features=5, out_features=1024, bias=True)\n",
        "      (LayerNorm): BertLayerNorm()\n",
        "      (dropout): Dropout(p=0.1, inplace=False)\n",
        "    )\n",
        "    (encoder): BertEncoder(\n",
        "      (layer): ModuleList(\n",
        "        (0): BertLayer(\n",
        "          (attention): BertAttention(\n",
        "            (self): BertSelfAttention(\n",
        "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
        "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
        "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
        "              (dropout): Dropout(p=0.1, inplace=False)\n",
        "            )\n",
        "            (output): BertSelfOutput(\n",
        "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
        "              (LayerNorm): BertLayerNorm()\n",
        "              (dropout): Dropout(p=0.1, inplace=False)\n",
        "            )\n",
        "          )\n",
        "          (intermediate): BertIntermediate(\n",
        "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
        "          )\n",
        "          (output): BertOutput(\n",
        "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
        "            (LayerNorm): BertLayerNorm()\n",
        "            (dropout): Dropout(p=0.1, inplace=False)\n",
        "          )\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "640xzupm0q5v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "4de41a85-10f3-499e-f081-3ae3b009407e"
      },
      "source": [
        "tkn = [\"she\", \"is\", \"beautiful\"]\n",
        "img = np.array([[1,2,3],[4,5,6]])\n",
        "# img = np.array([1,2,3, 4,5,6])\n",
        "# summary(model,(tkn, img, BertImageEmbeddings))\n",
        "summary(model,(tkn, img, img))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-bd5b91854dc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# img = np.array([1,2,3, 4,5,6])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# summary(model,(tkn, img, BertImageEmbeddings))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtkn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# batch_size of 2 for batchnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0min_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0min_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;31m# print(type(x[0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# batch_size of 2 for batchnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0min_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0min_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;31m# print(type(x[0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: rand(): argument 'size' must be tuple of ints, but found element of type list at pos 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "a3Fz995p6DEt",
        "outputId": "b15f4693-fa95-4b8a-c695-359ce3e3929c"
      },
      "source": [
        "summary(model,[500])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-15b6ce1fd7c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# batch_size of 2 for batchnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0min_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0min_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;31m# print(type(x[0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# batch_size of 2 for batchnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0min_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0min_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;31m# print(type(x[0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: rand() argument after * must be an iterable, not int"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82C5yd84xhME"
      },
      "source": [
        "## demo.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlxvuVuszbsU"
      },
      "source": [
        "### additional setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkMo4KAmqZa2"
      },
      "source": [
        "#### installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJCULWpkzad4"
      },
      "source": [
        "# first, make sure that your conda is setup properly with the right environment\n",
        "# for that, check that `which conda`, `which pip` and `which python` points to the\n",
        "# right path. From a clean conda env, this is what you need to do\n",
        "\n",
        "# !conda create --name maskrcnn_benchmark -y\n",
        "# !conda activate maskrcnn_benchmark\n",
        "\n",
        "# this installs the right pip and dependencies for the fresh python\n",
        "# !conda install ipython pip\n",
        "\n",
        "# maskrcnn_benchmark and coco api dependencies\n",
        "!pip install ninja yacs cython matplotlib tqdm opencv-python\n",
        "\n",
        "# follow PyTorch installation in https://pytorch.org/get-started/locally/\n",
        "# we give the instructions for CUDA 9.0\n",
        "!conda install -c pytorch pytorch-nightly torchvision cudatoolkit=9.0\n",
        "\n",
        "!export INSTALL_DIR=$PWD\n",
        "\n",
        "# install pycocotools\n",
        "%cd $INSTALL_DIR\n",
        "!git clone https://github.com/cocodataset/cocoapi.git\n",
        "%cd cocoapi/PythonAPI\n",
        "!python setup.py build_ext install\n",
        "\n",
        "# install cityscapesScripts\n",
        "%cd $INSTALL_DIR\n",
        "!git clone https://github.com/mcordts/cityscapesScripts.git\n",
        "%cd cityscapesScripts/\n",
        "!python setup.py build_ext install\n",
        "\n",
        "# # install apex\n",
        "# %cd $INSTALL_DIR\n",
        "# !git clone https://github.com/NVIDIA/apex.git\n",
        "# %cd apex\n",
        "# !python setup.py install --cuda_ext --cpp_ext\n",
        "\n",
        "# # install PyTorch Detection\n",
        "# %cd $INSTALL_DIR\n",
        "# !git clone https://github.com/facebookresearch/maskrcnn-benchmark.git\n",
        "# %cd maskrcnn-benchmark\n",
        "\n",
        "# # the following will install the lib with\n",
        "# # symbolic links, so that you can modify\n",
        "# # the files if you want and won't need to\n",
        "# # re-build it\n",
        "# !python setup.py build develop\n",
        "\n",
        "%cd /content/vilbert-multi-task\n",
        "\n",
        "!unset INSTALL_DIR\n",
        "\n",
        "# or if you are on macOS\n",
        "# MACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++ python setup.py build develop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0tePkcgqeZS"
      },
      "source": [
        "#### error handling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoYCrQeH1Lvm"
      },
      "source": [
        "# FileNotFoundError: [Errno 2] No such file or directory: 'save/resnext_models/e2e_faster_rcnn_X-152-32x8d-FPN_1x_MLP_2048_FPN_512_train.yaml'\n",
        "## https://github.com/facebookresearch/vilbert-multi-task/issues/6\n",
        "%cd /content/vilbert-multi-task\n",
        "!git clone https://gitlab.com/vedanuj/vqa-maskrcnn-benchmark\n",
        "%cd vqa-maskrcnn-benchmark\n",
        "!python setup.py build develop\n",
        "%cd ../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FNmpkr-qqcB",
        "outputId": "7358eec3-8c97-4003-ab21-d5af080246dc"
      },
      "source": [
        "# AttributeError: module 'torch._six' has no attribute 'PY3'\n",
        "## https://datascience.stackexchange.com/questions/13669/how-to-export-one-cell-of-a-jupyter-notebook\n",
        "# %%writefile maskrcnn-benchmark/maskrcnn_benchmark/utils/imports.py\n",
        "%%writefile vqa-maskrcnn-benchmark/maskrcnn_benchmark/utils/imports.py\n",
        "# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\n",
        "import torch\n",
        "dummy=False\n",
        "# if torch._six.PY3:\n",
        "if dummy:\n",
        "    import importlib\n",
        "    import importlib.util\n",
        "    import sys\n",
        "\n",
        "\n",
        "    # from https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa\n",
        "    def import_file(module_name, file_path, make_importable=False):\n",
        "        spec = importlib.util.spec_from_file_location(module_name, file_path)\n",
        "        module = importlib.util.module_from_spec(spec)\n",
        "        spec.loader.exec_module(module)\n",
        "        if make_importable:\n",
        "            sys.modules[module_name] = module\n",
        "        return module\n",
        "else:\n",
        "    import imp\n",
        "\n",
        "    def import_file(module_name, file_path, make_importable=None):\n",
        "        module = imp.load_source(module_name, file_path)\n",
        "        return module"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting vqa-maskrcnn-benchmark/maskrcnn_benchmark/utils/imports.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NLH514DWn5z",
        "outputId": "8e44bb9c-3ebd-4aba-a2ab-9eb6b074ff20"
      },
      "source": [
        "# move files to locations coressponding to demo.ipynb\n",
        "## FileNotFoundError: [Errno 2] No such file or directory: 'save/resnext_models/e2e_faster_rcnn_X-152-32x8d-FPN_1x_MLP_2048_FPN_512_train.yaml'\n",
        "# e2e_faster_rcnn_X-101-64x4d-FPN_1x_MLP_2048_FPN_512_test.yaml\n",
        "# e2e_faster_rcnn_X-101-64x4d-FPN_1x_MLP_2048_FPN_512_train.yaml\n",
        "# e2e_faster_rcnn_X-101-64x4d-FPN_1x_MLP_2048_FPN_512_vqa_test.yaml\n",
        "# e2e_faster_rcnn_X-101-64x4d-FPN_1x_MLP_2048_FPN_512_vqa_val.yaml\n",
        "# e2e_faster_rcnn_X-101-64x4d-FPN_1x_MLP_2048_FPN_512_vqa_train.yaml\n",
        "# e2e_faster_rcnn_X-152-32x8d-FPN_1x_MLP_2048_FPN_512_train.yaml \n",
        "# e2e_faster_rcnn_X-152-32x8d-FPN_1x_MLP_2048_FPN_512_test.yaml \n",
        "MODEL_NAME=\"e2e_faster_rcnn_X-101-64x4d-FPN_1x_MLP_2048_FPN_512_train.yaml\"\n",
        "!mkdir save\n",
        "!mkdir save/multitask_model\n",
        "%mv multi_task_model.bin save/multitask_model/pytorch_model_9.bin\n",
        "!mkdir save/resnext_models\n",
        "# %mv vqa-maskrcnn-benchmark/configs/visual_genome_vqa/e2e_faster_rcnn_X-152-32x8d-FPN_1x_MLP_2048_FPN_512_train.yaml save/resnext_models/e2e_faster_rcnn_X-152-32x8d-FPN_1x_MLP_2048_FPN_512_train.yaml\n",
        "%cd /content/vilbert-multi-task/vqa-maskrcnn-benchmark/configs/visual_genome_vqa/\n",
        "%mv e2e_faster_rcnn_X-101-64x4d-FPN_1x_MLP_2048_FPN_512_train.yaml /content/vilbert-multi-task/save/resnext_models/model.yaml\n",
        "%cd /content/vilbert-multi-task"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/vilbert-multi-task/vqa-maskrcnn-benchmark/configs/visual_genome_vqa\n",
            "/content/vilbert-multi-task\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4x3adQW3lv6"
      },
      "source": [
        "# no module named maskrcnn_benchmark\n",
        "## https://stackoverflow.com/questions/57899205/modulenotfounderror-no-module-named-maskrcnn-benchmark\n",
        "import sys\n",
        "sys.path.append('/content/vilbert-multi-task/vqa-maskrcnn-benchmark')\n",
        "\n",
        "### test\n",
        "from maskrcnn_benchmark.utils.env import setup_environment  # noqa F401 isort:skip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWDQ1NeUE45z",
        "outputId": "6234dc06-eac9-4d7a-9928-194558d9d85e"
      },
      "source": [
        "# FileNotFoundError: [Errno 2] No such file or directory: 'FAST_RCNN_MLP_DIM2048_FPN_DIM512.pkl'\n",
        "## https://github.com/gabegrand/pythia-1/blob/master/data_prep/data_preprocess.md\n",
        "## https://github.com/facebookresearch/mmf/issues/30\n",
        "!wget https://dl.fbaipublicfiles.com/pythia/detectron_model/FAST_RCNN_MLP_DIM2048_FPN_DIM512.pkl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-05 01:43:17--  https://dl.fbaipublicfiles.com/pythia/detectron_model/FAST_RCNN_MLP_DIM2048_FPN_DIM512.pkl\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1357496266 (1.3G) [application/octet-stream]\n",
            "Saving to: ‘FAST_RCNN_MLP_DIM2048_FPN_DIM512.pkl’\n",
            "\n",
            "FAST_RCNN_MLP_DIM20 100%[===================>]   1.26G  11.7MB/s    in 2m 0s   \n",
            "\n",
            "2021-04-05 01:45:18 (10.8 MB/s) - ‘FAST_RCNN_MLP_DIM2048_FPN_DIM512.pkl’ saved [1357496266/1357496266]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7Dxeo1AF42P",
        "outputId": "a0837782-ca8c-4d81-ae47-5fbc2f31051f"
      },
      "source": [
        "%%writefile vqa-maskrcnn-benchmark/maskrcnn_benchmark/utils/c2_model_loading.py\n",
        "# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\n",
        "import logging\n",
        "import pickle\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "\n",
        "from maskrcnn_benchmark.utils.model_serialization import load_state_dict\n",
        "from maskrcnn_benchmark.utils.registry import Registry\n",
        "\n",
        "\n",
        "def _rename_basic_resnet_weights(layer_keys):\n",
        "    layer_keys = [k.replace(\"_\", \".\") for k in layer_keys]\n",
        "    layer_keys = [k.replace(\".w\", \".weight\") for k in layer_keys]\n",
        "    layer_keys = [k.replace(\".bn\", \"_bn\") for k in layer_keys]\n",
        "    layer_keys = [k.replace(\".b\", \".bias\") for k in layer_keys]\n",
        "    layer_keys = [k.replace(\"_bn.s\", \"_bn.scale\") for k in layer_keys]\n",
        "    layer_keys = [k.replace(\".biasranch\", \".branch\") for k in layer_keys]\n",
        "    layer_keys = [k.replace(\"bbox.pred\", \"bbox_pred\") for k in layer_keys]\n",
        "    layer_keys = [k.replace(\"cls.score\", \"cls_score\") for k in layer_keys]\n",
        "    layer_keys = [k.replace(\"res.conv1_\", \"conv1_\") for k in layer_keys]\n",
        "\n",
        "    # RPN / Faster RCNN\n",
        "    layer_keys = [k.replace(\".biasbox\", \".bbox\") for k in layer_keys]\n",
        "    layer_keys = [k.replace(\"conv.rpn\", \"rpn.conv\") for k in layer_keys]\n",
        "    layer_keys = [k.replace(\"rpn.bbox.pred\", \"rpn.bbox_pred\") for k in layer_keys]\n",
        "    layer_keys = [k.replace(\"rpn.cls.logits\", \"rpn.cls_logits\") for k in layer_keys]\n",
        "\n",
        "    # Affine-Channel -> BatchNorm enaming\n",
        "    layer_keys = [k.replace(\"_bn.scale\", \"_bn.weight\") for k in layer_keys]\n",
        "\n",
        "    # Make torchvision-compatible\n",
        "    layer_keys = [k.replace(\"conv1_bn.\", \"bn1.\") for k in layer_keys]\n",
        "\n",
        "    layer_keys = [k.replace(\"res2.\", \"layer1.\") for k in layer_keys]\n",
        "    layer_keys = [k.replace(\"res3.\", \"layer2.\") for k in layer_keys]\n",
        "    layer_keys = [k.replace(\"res4.\", \"layer3.\") for k in layer_keys]\n",
        "    layer_keys = [k.replace(\"res5.\", \"layer4.\") for k in layer_keys]\n",
        "\n",
        "    layer_keys = [k.replace(\".branch2a.\", \".conv1.\") for k in layer_keys]\n",
        "    layer_keys = [k.replace(\".branch2a_bn.\", \".bn1.\") for k in layer_keys]\n",
        "    layer_keys = [k.replace(\".branch2b.\", \".conv2.\") for k in layer_keys]\n",
        "    layer_keys = [k.replace(\".branch2b_bn.\", \".bn2.\") for k in layer_keys]\n",
        "    layer_keys = [k.replace(\".branch2c.\", \".conv3.\") for k in layer_keys]\n",
        "    layer_keys = [k.replace(\".branch2c_bn.\", \".bn3.\") for k in layer_keys]\n",
        "\n",
        "    layer_keys = [k.replace(\".branch1.\", \".downsample.0.\") for k in layer_keys]\n",
        "    layer_keys = [k.replace(\".branch1_bn.\", \".downsample.1.\") for k in layer_keys]\n",
        "\n",
        "    return layer_keys\n",
        "\n",
        "\n",
        "def _rename_fpn_weights(layer_keys, stage_names):\n",
        "    for mapped_idx, stage_name in enumerate(stage_names, 1):\n",
        "        suffix = \"\"\n",
        "        if mapped_idx < 4:\n",
        "            suffix = \".lateral\"\n",
        "        layer_keys = [\n",
        "            k.replace(\n",
        "                \"fpn.inner.layer{}.sum{}\".format(stage_name, suffix),\n",
        "                \"fpn_inner{}\".format(mapped_idx),\n",
        "            )\n",
        "            for k in layer_keys\n",
        "        ]\n",
        "        layer_keys = [\n",
        "            k.replace(\"fpn.layer{}.sum\".format(stage_name), \"fpn_layer{}\".format(mapped_idx))\n",
        "            for k in layer_keys\n",
        "        ]\n",
        "\n",
        "    layer_keys = [k.replace(\"rpn.conv.fpn2\", \"rpn.conv\") for k in layer_keys]\n",
        "    layer_keys = [k.replace(\"rpn.bbox_pred.fpn2\", \"rpn.bbox_pred\") for k in layer_keys]\n",
        "    layer_keys = [k.replace(\"rpn.cls_logits.fpn2\", \"rpn.cls_logits\") for k in layer_keys]\n",
        "\n",
        "    return layer_keys\n",
        "\n",
        "\n",
        "def _rename_weights_for_resnet(weights, stage_names):\n",
        "    original_keys = sorted(weights.keys())\n",
        "    layer_keys = sorted(weights.keys())\n",
        "\n",
        "    # for X-101, rename output to fc1000 to avoid conflicts afterwards\n",
        "    layer_keys = [k if k != \"pred_b\" else \"fc1000_b\" for k in layer_keys]\n",
        "    layer_keys = [k if k != \"pred_w\" else \"fc1000_w\" for k in layer_keys]\n",
        "\n",
        "    # performs basic renaming: _ -> . , etc\n",
        "    layer_keys = _rename_basic_resnet_weights(layer_keys)\n",
        "\n",
        "    # FPN\n",
        "    layer_keys = _rename_fpn_weights(layer_keys, stage_names)\n",
        "\n",
        "    # Mask R-CNN\n",
        "    layer_keys = [k.replace(\"mask.fcn.logits\", \"mask_fcn_logits\") for k in layer_keys]\n",
        "    layer_keys = [k.replace(\".[mask].fcn\", \"mask_fcn\") for k in layer_keys]\n",
        "    layer_keys = [k.replace(\"conv5.mask\", \"conv5_mask\") for k in layer_keys]\n",
        "\n",
        "    # Keypoint R-CNN\n",
        "    layer_keys = [k.replace(\"kps.score.lowres\", \"kps_score_lowres\") for k in layer_keys]\n",
        "    layer_keys = [k.replace(\"kps.score\", \"kps_score\") for k in layer_keys]\n",
        "    layer_keys = [k.replace(\"conv.fcn\", \"conv_fcn\") for k in layer_keys]\n",
        "\n",
        "    # Rename for our RPN structure\n",
        "    layer_keys = [k.replace(\"rpn.\", \"rpn.head.\") for k in layer_keys]\n",
        "\n",
        "    key_map = {k: v for k, v in zip(original_keys, layer_keys)}\n",
        "\n",
        "    logger = logging.getLogger(__name__)\n",
        "    logger.info(\"Remapping C2 weights\")\n",
        "    max_c2_key_size = max([len(k) for k in original_keys if \"_momentum\" not in k])\n",
        "\n",
        "    new_weights = OrderedDict()\n",
        "    for k in original_keys:\n",
        "        v = weights[k]\n",
        "        if \"_momentum\" in k:\n",
        "            continue\n",
        "        # if 'fc1000' in k:\n",
        "        #     continue\n",
        "        if v == \"BGR\":\n",
        "            continue\n",
        "        w = torch.from_numpy(v)\n",
        "        # if \"bn\" in k:\n",
        "        #     w = w.view(1, -1, 1, 1)\n",
        "        logger.info(\"C2 name: {: <{}} mapped name: {}\".format(k, max_c2_key_size, key_map[k]))\n",
        "        new_weights[key_map[k]] = w\n",
        "\n",
        "    return new_weights\n",
        "\n",
        "\n",
        "def _load_c2_pickled_weights(file_path):\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        dummy=True#False results in UnicodeDecodeError\n",
        "        if dummy:\n",
        "            data = pickle.load(f, encoding=\"latin1\")\n",
        "        else:\n",
        "            data = pickle.load(f)\n",
        "    if \"blobs\" in data:\n",
        "        weights = data[\"blobs\"]\n",
        "    else:\n",
        "        weights = data\n",
        "    return weights\n",
        "\n",
        "\n",
        "_C2_STAGE_NAMES = {\n",
        "    \"R-50\": [\"1.2\", \"2.3\", \"3.5\", \"4.2\"], \n",
        "    \"R-101\": [\"1.2\", \"2.3\", \"3.22\", \"4.2\"], \n",
        "    \"R-152\": [\"1.2\", \"2.7\", \"3.35\", \"4.2\"]\n",
        "}\n",
        "\n",
        "C2_FORMAT_LOADER = Registry()\n",
        "\n",
        "\n",
        "@C2_FORMAT_LOADER.register(\"R-50-C4\")\n",
        "@C2_FORMAT_LOADER.register(\"R-50-FPN\")\n",
        "@C2_FORMAT_LOADER.register(\"R-101-FPN\")\n",
        "@C2_FORMAT_LOADER.register(\"R-152-FPN\")\n",
        "def load_resnet_c2_format(cfg, f):\n",
        "    state_dict = _load_c2_pickled_weights(f)\n",
        "    conv_body = cfg.MODEL.BACKBONE.CONV_BODY\n",
        "    arch = conv_body.replace(\"-C4\", \"\").replace(\"-FPN\", \"\")\n",
        "    stages = _C2_STAGE_NAMES[arch]\n",
        "    state_dict = _rename_weights_for_resnet(state_dict, stages)\n",
        "    return dict(model=state_dict)\n",
        "\n",
        "\n",
        "def load_c2_format(cfg, f):\n",
        "    return C2_FORMAT_LOADER[cfg.MODEL.BACKBONE.CONV_BODY](cfg, f)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting vqa-maskrcnn-benchmark/maskrcnn_benchmark/utils/c2_model_loading.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RY-pZk_HCkL4",
        "outputId": "2aad11f1-8987-4db9-c19f-6777a634e5da"
      },
      "source": [
        "# FileNotFoundError: [Errno 2] No such file or directory: 'save/resnext_models/model_final.pth'\n",
        "## https://gitlab.com/vedanuj/vqa-maskrcnn-benchmark/-/blob/master/tools/c2_to_pt.py\n",
        "import os\n",
        "\n",
        "import torch as t\n",
        "from maskrcnn_benchmark.config import cfg\n",
        "from maskrcnn_benchmark.utils.c2_model_loading import load_c2_format\n",
        "\n",
        "path = \"FAST_RCNN_MLP_DIM2048_FPN_DIM512.pkl\"\n",
        "config_name = 'modified_for_conversion_e2e_faster_rcnn_X-101-64x4d-FPN_1x_MLP_2048_FPN_512.yaml'\n",
        "base_path = '/content/vilbert-multi-task/vqa-maskrcnn-benchmark/configs/visual_genome_vqa/c2'\n",
        "# base_path = '/content/vilbert-multi-task/save/visual_genome_vqa/c2'\n",
        "\n",
        "cfg.merge_from_file(os.path.join(base_path, config_name))\n",
        "\n",
        "_d = load_c2_format(cfg, path)\n",
        "newdict = _d\n",
        "t.save(newdict, \"save/resnext_models/model_final.pth\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/vilbert-multi-task/vqa-maskrcnn-benchmark/maskrcnn_benchmark/utils/c2_model_loading.py:117: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  if v == \"BGR\":\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1mQj0aa_ZDL"
      },
      "source": [
        "#### run notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0v2VJosdfiQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d35ee6a-d3bb-4f2d-de29-279ff2e0bb22"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import yaml\n",
        "\n",
        "from easydict import EasyDict as edict\n",
        "from pytorch_transformers.tokenization_bert import BertTokenizer\n",
        "from vilbert.datasets import ConceptCapLoaderTrain, ConceptCapLoaderVal\n",
        "from vilbert.vilbert import VILBertForVLTasks, BertConfig, BertForMultiModalPreTraining\n",
        "from vilbert.task_utils import LoadDatasetEval\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "\n",
        "from maskrcnn_benchmark.config import cfg\n",
        "from maskrcnn_benchmark.layers import nms\n",
        "from maskrcnn_benchmark.modeling.detector import build_detection_model\n",
        "from maskrcnn_benchmark.structures.image_list import to_image_list\n",
        "from maskrcnn_benchmark.utils.model_serialization import load_state_dict\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import argparse\n",
        "import glob\n",
        "from types import SimpleNamespace\n",
        "import pdb\n",
        "\n",
        "%matplotlib inline  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "04/05/2021 01:45:25 - INFO - vilbert.vilbert -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhY50d-eyIpX"
      },
      "source": [
        "class FeatureExtractor:\n",
        "    MAX_SIZE = 1333\n",
        "    # MIN_SIZE = 800\n",
        "    MIN_SIZE = 10\n",
        "\n",
        "    def __init__(self):\n",
        "        self.args = self.get_parser()\n",
        "        self.detection_model = self._build_detection_model()\n",
        "\n",
        "    def get_parser(self):        \n",
        "        parser = SimpleNamespace(model_file= 'save/resnext_models/model_final.pth',\n",
        "                                #config_file='save/resnext_models/e2e_faster_rcnn_X-152-32x8d-FPN_1x_MLP_2048_FPN_512_train.yaml',\n",
        "                                #config_file=os.path.join(\"save/resnext_models/\", MODEL_NAME), \n",
        "                                config_file=os.path.join(\"save/resnext_models/model.yaml\"), \n",
        "                                batch_size=1,\n",
        "                                num_features=100,\n",
        "                                feature_name=\"fc6\",\n",
        "                                confidence_threshold=0,\n",
        "                                background=False,\n",
        "                                partition=0)\n",
        "        return parser\n",
        "    \n",
        "    def _build_detection_model(self):\n",
        "        cfg.merge_from_file(self.args.config_file)\n",
        "        cfg.freeze()\n",
        "\n",
        "        model = build_detection_model(cfg)\n",
        "        checkpoint = torch.load(self.args.model_file, map_location=torch.device(\"cpu\"))\n",
        "\n",
        "        load_state_dict(model, checkpoint.pop(\"model\"))\n",
        "\n",
        "        model.to(\"cuda\")\n",
        "        model.eval()\n",
        "        return model\n",
        "\n",
        "    def _image_transform(self, path):\n",
        "        img = Image.open(path)\n",
        "        im = np.array(img).astype(np.float32)\n",
        "        # IndexError: too many indices for array, grayscale images\n",
        "        if len(im.shape) < 3:\n",
        "            im = np.repeat(im[:, :, np.newaxis], 3, axis=2)\n",
        "        im = im[:, :, ::-1]\n",
        "        im -= np.array([102.9801, 115.9465, 122.7717])\n",
        "        im_shape = im.shape\n",
        "        im_height = im_shape[0]\n",
        "        im_width = im_shape[1]\n",
        "        im_size_min = np.min(im_shape[0:2])\n",
        "        im_size_max = np.max(im_shape[0:2])\n",
        "\n",
        "        # Scale based on minimum size\n",
        "        im_scale = self.MIN_SIZE / im_size_min\n",
        "\n",
        "        # Prevent the biggest axis from being more than max_size\n",
        "        # If bigger, scale it down\n",
        "        if np.round(im_scale * im_size_max) > self.MAX_SIZE:\n",
        "            im_scale = self.MAX_SIZE / im_size_max\n",
        "\n",
        "        im = cv2.resize(\n",
        "            im, None, None, fx=im_scale, fy=im_scale, interpolation=cv2.INTER_LINEAR\n",
        "        )\n",
        "        img = torch.from_numpy(im).permute(2, 0, 1)\n",
        "\n",
        "        im_info = {\"width\": im_width, \"height\": im_height}\n",
        "\n",
        "        return img, im_scale, im_info\n",
        "\n",
        "    def _process_feature_extraction(\n",
        "        self, output, im_scales, im_infos, feature_name=\"fc6\", conf_thresh=0\n",
        "    ):\n",
        "        batch_size = len(output[0][\"proposals\"])\n",
        "        n_boxes_per_image = [len(boxes) for boxes in output[0][\"proposals\"]]\n",
        "        score_list = output[0][\"scores\"].split(n_boxes_per_image)\n",
        "        score_list = [torch.nn.functional.softmax(x, -1) for x in score_list]\n",
        "        feats = output[0][feature_name].split(n_boxes_per_image)\n",
        "        cur_device = score_list[0].device\n",
        "\n",
        "        feat_list = []\n",
        "        info_list = []\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            dets = output[0][\"proposals\"][i].bbox / im_scales[i]\n",
        "            scores = score_list[i]\n",
        "            max_conf = torch.zeros((scores.shape[0])).to(cur_device)\n",
        "            conf_thresh_tensor = torch.full_like(max_conf, conf_thresh)\n",
        "            start_index = 1\n",
        "            # Column 0 of the scores matrix is for the background class\n",
        "            if self.args.background:\n",
        "                start_index = 0\n",
        "            for cls_ind in range(start_index, scores.shape[1]):\n",
        "                cls_scores = scores[:, cls_ind]\n",
        "                keep = nms(dets, cls_scores, 0.5)\n",
        "                max_conf[keep] = torch.where(\n",
        "                    # Better than max one till now and minimally greater than conf_thresh\n",
        "                    (cls_scores[keep] > max_conf[keep])\n",
        "                    & (cls_scores[keep] > conf_thresh_tensor[keep]),\n",
        "                    cls_scores[keep],\n",
        "                    max_conf[keep],\n",
        "                )\n",
        "\n",
        "            sorted_scores, sorted_indices = torch.sort(max_conf, descending=True)\n",
        "            num_boxes = (sorted_scores[: self.args.num_features] != 0).sum()\n",
        "            keep_boxes = sorted_indices[: self.args.num_features]\n",
        "            feat_list.append(feats[i][keep_boxes])\n",
        "            bbox = output[0][\"proposals\"][i][keep_boxes].bbox / im_scales[i]\n",
        "            # Predict the class label using the scores\n",
        "            objects = torch.argmax(scores[keep_boxes][start_index:], dim=1)\n",
        "            cls_prob = torch.max(scores[keep_boxes][start_index:], dim=1)\n",
        "\n",
        "            info_list.append(\n",
        "                {\n",
        "                    \"bbox\": bbox.cpu().numpy(),\n",
        "                    \"num_boxes\": num_boxes.item(),\n",
        "                    \"objects\": objects.cpu().numpy(),\n",
        "                    \"image_width\": im_infos[i][\"width\"],\n",
        "                    \"image_height\": im_infos[i][\"height\"],\n",
        "                    \"cls_prob\": scores[keep_boxes].cpu().numpy(),\n",
        "                }\n",
        "            )\n",
        "\n",
        "        return feat_list, info_list\n",
        "\n",
        "    def get_detectron_features(self, image_paths):\n",
        "        img_tensor, im_scales, im_infos = [], [], []\n",
        "\n",
        "        for image_path in image_paths:\n",
        "            im, im_scale, im_info = self._image_transform(image_path)\n",
        "            img_tensor.append(im)\n",
        "            im_scales.append(im_scale)\n",
        "            im_infos.append(im_info)\n",
        "\n",
        "        # Image dimensions should be divisible by 32, to allow convolutions\n",
        "        # in detector to work\n",
        "        current_img_list = to_image_list(img_tensor, size_divisible=32)\n",
        "        current_img_list = current_img_list.to(\"cuda\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = self.detection_model(current_img_list)\n",
        "\n",
        "        feat_list = self._process_feature_extraction(\n",
        "            output,\n",
        "            im_scales,\n",
        "            im_infos,\n",
        "            self.args.feature_name,\n",
        "            self.args.confidence_threshold,\n",
        "        )\n",
        "\n",
        "        return feat_list\n",
        "\n",
        "    def _chunks(self, array, chunk_size):\n",
        "        for i in range(0, len(array), chunk_size):\n",
        "            yield array[i : i + chunk_size]\n",
        "\n",
        "    def _save_feature(self, file_name, feature, info):\n",
        "        file_base_name = os.path.basename(file_name)\n",
        "        file_base_name = file_base_name.split(\".\")[0]\n",
        "        info[\"image_id\"] = file_base_name\n",
        "        info[\"features\"] = feature.cpu().numpy()\n",
        "        file_base_name = file_base_name + \".npy\"\n",
        "\n",
        "        np.save(os.path.join(self.args.output_folder, file_base_name), info)\n",
        "\n",
        "    def extract_features(self, image_path):\n",
        "\n",
        "        features, infos = self.get_detectron_features([image_path])\n",
        "\n",
        "        return features, infos\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsH6GmWnyI8v"
      },
      "source": [
        "def tokenize_batch(batch):\n",
        "    return [tokenizer.convert_tokens_to_ids(sent) for sent in batch]\n",
        "\n",
        "def untokenize_batch(batch):\n",
        "    return [tokenizer.convert_ids_to_tokens(sent) for sent in batch]\n",
        "\n",
        "def detokenize(sent):\n",
        "    \"\"\" Roughly detokenizes (mainly undoes wordpiece) \"\"\"\n",
        "    new_sent = []\n",
        "    for i, tok in enumerate(sent):\n",
        "        if tok.startswith(\"##\"):\n",
        "            new_sent[len(new_sent) - 1] = new_sent[len(new_sent) - 1] + tok[2:]\n",
        "        else:\n",
        "            new_sent.append(tok)\n",
        "    return new_sent\n",
        "\n",
        "def printer(sent, should_detokenize=True):\n",
        "    if should_detokenize:\n",
        "        sent = detokenize(sent)[1:-1]\n",
        "    print(\" \".join(sent))\n",
        "\n",
        "\n",
        "# write arbitary string for given sentense. \n",
        "import _pickle as cPickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUOq14K-yQsk"
      },
      "source": [
        "def prediction(question, features, spatials, segment_ids, input_mask, image_mask, co_attention_mask, task_tokens, ):\n",
        "\n",
        "    vil_prediction, vil_prediction_gqa, vil_logit, vil_binary_prediction, vil_tri_prediction, vision_prediction, vision_logit, linguisic_prediction, linguisic_logit, attn_data_list = model(\n",
        "        question, features, spatials, segment_ids, input_mask, image_mask, co_attention_mask, task_tokens, output_all_attention_masks=True\n",
        "    )\n",
        "    \n",
        "    height, width = img.shape[0], img.shape[1]\n",
        "\n",
        "    logits = torch.max(vil_prediction, 1)[1].data  # argmax\n",
        "    # Load VQA label to answers:\n",
        "    label2ans_path = os.path.join('save', \"VQA\" ,\"cache\", \"trainval_label2ans.pkl\")\n",
        "    vqa_label2ans = cPickle.load(open(label2ans_path, \"rb\"))\n",
        "    answer = vqa_label2ans[logits[0].item()]\n",
        "    print(\"VQA: \" + answer)\n",
        "\n",
        "    # Load GQA label to answers:\n",
        "    label2ans_path = os.path.join('save', \"gqa\" ,\"cache\", \"trainval_label2ans.pkl\")\n",
        "\n",
        "    logtis_gqa = torch.max(vil_prediction_gqa, 1)[1].data\n",
        "    gqa_label2ans = cPickle.load(open(label2ans_path, \"rb\"))\n",
        "    answer = gqa_label2ans[logtis_gqa[0].item()]\n",
        "    print(\"GQA: \" + answer)\n",
        "\n",
        "    # vil_binary_prediction NLVR2, 0: False 1: True Task 12\n",
        "    logtis_binary = torch.max(vil_binary_prediction, 1)[1].data\n",
        "    print(\"NLVR: \" + str(logtis_binary.item()))\n",
        "\n",
        "    # vil_entaliment:  \n",
        "    label_map = {0:\"contradiction\", 1:\"neutral\", 2:\"entailment\"}\n",
        "    logtis_tri = torch.max(vil_tri_prediction, 1)[1].data\n",
        "    print(\"Entaliment: \" + str(label_map[logtis_tri.item()]))\n",
        "\n",
        "    # vil_logit: \n",
        "    logits_vil = vil_logit[0].item()\n",
        "    print(\"ViL_logit: %f\" %logits_vil)\n",
        "\n",
        "    # grounding: \n",
        "    logits_vision = torch.max(vision_logit, 1)[1].data\n",
        "    grounding_val, grounding_idx = torch.sort(vision_logit.view(-1), 0, True)\n",
        "\n",
        "    examples_per_row = 5\n",
        "    ncols = examples_per_row \n",
        "    nrows = 1\n",
        "    figsize = [12, ncols*20]     # figure size, inches\n",
        "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n",
        "\n",
        "    for i, axi in enumerate(ax.flat):\n",
        "        idx = grounding_idx[i]\n",
        "        val = grounding_val[i]\n",
        "        box = spatials[0][idx][:4].tolist()\n",
        "        y1 = int(box[1] * height)\n",
        "        y2 = int(box[3] * height)\n",
        "        x1 = int(box[0] * width)\n",
        "        x2 = int(box[2] * width)\n",
        "        patch = img[y1:y2,x1:x2]\n",
        "        axi.imshow(patch)\n",
        "        axi.axis('off')\n",
        "        axi.set_title(str(i) + \": \" + str(val.item()))\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout(True)\n",
        "    plt.show()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKnI6uxHyShW"
      },
      "source": [
        "def custom_prediction(query, task, features, infos):\n",
        "\n",
        "    tokens = tokenizer.encode(query)\n",
        "    tokens = tokenizer.add_special_tokens_single_sentence(tokens)\n",
        "\n",
        "    segment_ids = [0] * len(tokens)\n",
        "    input_mask = [1] * len(tokens)\n",
        "\n",
        "    max_length = 37\n",
        "    if len(tokens) < max_length:\n",
        "        # Note here we pad in front of the sentence\n",
        "        padding = [0] * (max_length - len(tokens))\n",
        "        tokens = tokens + padding\n",
        "        input_mask += padding\n",
        "        segment_ids += padding\n",
        "\n",
        "    text = torch.from_numpy(np.array(tokens)).cuda().unsqueeze(0)\n",
        "    input_mask = torch.from_numpy(np.array(input_mask)).cuda().unsqueeze(0)\n",
        "    segment_ids = torch.from_numpy(np.array(segment_ids)).cuda().unsqueeze(0)\n",
        "    task = torch.from_numpy(np.array(task)).cuda().unsqueeze(0)\n",
        "\n",
        "    num_image = len(infos)\n",
        "\n",
        "    feature_list = []\n",
        "    image_location_list = []\n",
        "    image_mask_list = []\n",
        "    for i in range(num_image):\n",
        "        image_w = infos[i]['image_width']\n",
        "        image_h = infos[i]['image_height']\n",
        "        feature = features[i]\n",
        "        num_boxes = feature.shape[0]\n",
        "\n",
        "        g_feat = torch.sum(feature, dim=0) / num_boxes\n",
        "        num_boxes = num_boxes + 1\n",
        "        feature = torch.cat([g_feat.view(1,-1), feature], dim=0)\n",
        "        boxes = infos[i]['bbox']\n",
        "        image_location = np.zeros((boxes.shape[0], 5), dtype=np.float32)\n",
        "        image_location[:,:4] = boxes\n",
        "        image_location[:,4] = (image_location[:,3] - image_location[:,1]) * (image_location[:,2] - image_location[:,0]) / (float(image_w) * float(image_h))\n",
        "        image_location[:,0] = image_location[:,0] / float(image_w)\n",
        "        image_location[:,1] = image_location[:,1] / float(image_h)\n",
        "        image_location[:,2] = image_location[:,2] / float(image_w)\n",
        "        image_location[:,3] = image_location[:,3] / float(image_h)\n",
        "        g_location = np.array([0,0,1,1,1])\n",
        "        image_location = np.concatenate([np.expand_dims(g_location, axis=0), image_location], axis=0)\n",
        "        image_mask = [1] * (int(num_boxes))\n",
        "\n",
        "        feature_list.append(feature)\n",
        "        image_location_list.append(torch.tensor(image_location))\n",
        "        image_mask_list.append(torch.tensor(image_mask))\n",
        "\n",
        "    features = torch.stack(feature_list, dim=0).float().cuda()\n",
        "    spatials = torch.stack(image_location_list, dim=0).float().cuda()\n",
        "    image_mask = torch.stack(image_mask_list, dim=0).byte().cuda()\n",
        "    co_attention_mask = torch.zeros((num_image, num_boxes, max_length)).cuda()\n",
        "\n",
        "    prediction(text, features, spatials, segment_ids, input_mask, image_mask, co_attention_mask, task)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wemBNjEyUb2"
      },
      "source": [
        "\n",
        "# =============================\n",
        "# ViLBERT part\n",
        "# =============================\n",
        "feature_extractor = FeatureExtractor()\n",
        "\n",
        "args = SimpleNamespace(from_pretrained= \"save/multitask_model/pytorch_model_9.bin\",\n",
        "                       bert_model=\"bert-base-uncased\",\n",
        "                       config_file=\"config/bert_base_6layer_6conect.json\",\n",
        "                       max_seq_length=101,\n",
        "                       train_batch_size=1,\n",
        "                       do_lower_case=True,\n",
        "                       predict_feature=False,\n",
        "                       seed=42,\n",
        "                       num_workers=0,\n",
        "                       baseline=False,\n",
        "                       img_weight=1,\n",
        "                       distributed=False,\n",
        "                       objective=1,\n",
        "                       visual_target=0,\n",
        "                       dynamic_attention=False,\n",
        "                       task_specific_tokens=True,\n",
        "                       tasks='1',\n",
        "                       save_name='',\n",
        "                       in_memory=False,\n",
        "                       batch_size=1,\n",
        "                       local_rank=-1,\n",
        "                       split='mteval',\n",
        "                       clean_train_sets=True\n",
        "                      )\n",
        "\n",
        "config = BertConfig.from_json_file(args.config_file)\n",
        "with open('./vilbert_tasks.yml', 'r') as f:\n",
        "    task_cfg = edict(yaml.safe_load(f))\n",
        "\n",
        "task_names = []\n",
        "for i, task_id in enumerate(args.tasks.split('-')):\n",
        "    task = 'TASK' + task_id\n",
        "    name = task_cfg[task]['name']\n",
        "    task_names.append(name)\n",
        "\n",
        "timeStamp = args.from_pretrained.split('/')[-1] + '-' + args.save_name\n",
        "config = BertConfig.from_json_file(args.config_file)\n",
        "default_gpu=True\n",
        "\n",
        "if args.predict_feature:\n",
        "    config.v_target_size = 2048\n",
        "    config.predict_feature = True\n",
        "else:\n",
        "    config.v_target_size = 1601\n",
        "    config.predict_feature = False\n",
        "\n",
        "if args.task_specific_tokens:\n",
        "    config.task_specific_tokens = True    \n",
        "\n",
        "if args.dynamic_attention:\n",
        "    config.dynamic_attention = True\n",
        "\n",
        "config.visualization = True\n",
        "num_labels = 3129\n",
        "\n",
        "if args.baseline:\n",
        "    model = BaseBertForVLTasks.from_pretrained(\n",
        "        args.from_pretrained, config=config, num_labels=num_labels, default_gpu=default_gpu\n",
        "        )\n",
        "else:\n",
        "    model = VILBertForVLTasks.from_pretrained(\n",
        "        args.from_pretrained, config=config, num_labels=num_labels, default_gpu=default_gpu\n",
        "        )\n",
        "    \n",
        "model.eval()\n",
        "cuda = torch.cuda.is_available()\n",
        "if cuda: model = model.cuda(0)\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    args.bert_model, do_lower_case=args.do_lower_case\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGEROH0gyXD2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "0b4387ed-26ae-4363-8e4c-e451a5cfe46d"
      },
      "source": [
        "# 1: VQA, 2: GenomeQA, 4: Visual7w, 7: Retrieval COCO, 8: Retrieval Flickr30k \n",
        "# 9: refcoco, 10: refcoco+ 11: refcocog, 12: NLVR2, 13: VisualEntailment, 15: GQA, 16: GuessWhat, \n",
        "\n",
        "\n",
        "image_path = 'demo/1.jpg'\n",
        "features, infos = feature_extractor.extract_features(image_path)\n",
        "\n",
        "img = PIL.Image.open(image_path).convert('RGB')\n",
        "img = torch.tensor(np.array(img))\n",
        "\n",
        "plt.axis('off')\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "    \n",
        "query = \"swimming elephant\"\n",
        "task = [9]\n",
        "custom_prediction(query, task, features, infos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-af2245ff7ddc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'demo/1.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-8fae1b994812>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, image_path)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_detectron_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-8fae1b994812>\u001b[0m in \u001b[0;36mget_detectron_features\u001b[0;34m(self, image_paths)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetection_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_img_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         feat_list = self._process_feature_extraction(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/vilbert-multi-task/vqa-maskrcnn-benchmark/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets, proposals)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mproposal_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroi_heads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetector_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroi_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;31m# RPN-only models don't have roi_heads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/vilbert-multi-task/vqa-maskrcnn-benchmark/maskrcnn_benchmark/modeling/roi_heads/roi_heads.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features, proposals, targets)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# TODO rename x to roi_box_features, if it doesn't increase memory consumption\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_box\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMASK_ON\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/vilbert-multi-task/vqa-maskrcnn-benchmark/maskrcnn_benchmark/modeling/roi_heads/box_head/box_head.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features, proposals, targets)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_feats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_attributes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mout_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0mattr_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attr_score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/vilbert-multi-task/vqa-maskrcnn-benchmark/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_predictors.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, proposals)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;31m# get labels and indices of proposals with foreground\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mall_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_field\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0mfg_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_labels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mfg_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfg_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/vilbert-multi-task/vqa-maskrcnn-benchmark/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_predictors.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;31m# get labels and indices of proposals with foreground\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mall_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_field\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0mfg_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_labels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mfg_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfg_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/vilbert-multi-task/vqa-maskrcnn-benchmark/maskrcnn_benchmark/structures/bounding_box.py\u001b[0m in \u001b[0;36mget_field\u001b[0;34m(self, field)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_field\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_fields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhas_field\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'labels'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dopiqNx-NOsj"
      },
      "source": [
        "## summary\n",
        "- one issue remaining, however it seems is raised from another repository, therefore just ignore it for now and proceed\n",
        "  - https://github.com/facebookresearch/vilbert-multi-task/issues/90"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xx8vUg02irYJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}